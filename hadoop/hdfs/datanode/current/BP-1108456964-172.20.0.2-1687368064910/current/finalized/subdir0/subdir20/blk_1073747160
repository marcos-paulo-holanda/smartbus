
C
6hadoop.security.group.mapping.ldap.posix.attr.uid.name	uidNumber
"
dfs.block.invalidate.limit1000

yarn.admin.acl*
7
/hive.repl.dump.metadata.only.for.external.tabletrue
%
hive.exec.stagingdir.hive-staging

hive.druid.rolluptrue
 
yarn.federation.enabledfalse
;
2yarn.app.mapreduce.am.job.committer.cancel-timeout60000
/
(dfs.namenode.audit.log.async.buffer.size128
3
!hive.druid.broker.address.defaultlocalhost:8082
5
/dfs.disk.balancer.max.disk.throughputInMBperSec10

mapred.mapper.new-apifalse
5
,dfs.qjournal.select-input-streams.timeout.ms20000
&
hive.llap.io.orc.time.counterstrue
'
hive.repl.retain.prev.dump.dirfalse
H
?hive.vectorized.execution.mapjoin.native.fast.hashtable.enabledfalse
2
*dfs.provided.aliasmap.inmemory.leveldb.dir/tmp
+
"hive.log.explain.output.to.consolefalse
1
'yarn.nodemanager.health-checker.scriptsscript
-
%yarn.nodemanager.process-kill-wait.ms5000
!
yarn.minicluster.use-rpcfalse
,
$hive.server2.wm.delayed.move.timeout3600

io.map.index.interval128
C
=hive.vectorized.execution.mapjoin.overflow.repeated.threshold-1
%
hive.server2.metrics.enabledfalse
'
yarn.webapp.api-service.enablefalse
$
hive.privilege.synchronizerfalse
5
0yarn.nodemanager.aux-services.manifest.reload-ms0
(
#hive.metastore.wm.default.pool.size4
&
dfs.provided.storage.idDS-PROVIDED
 
fs.s3a.path.style.accesstrue
3
#dfs.federation.router.admin-address0.0.0.0:8111
0
%dfs.namenode.fs-limits.min-block-size1048576
 
hive.tez.hs2.user.accesstrue
2
-mapreduce.input.fileinputformat.split.minsize1
0
+mapreduce.job.end-notification.max.attempts5
/
)fs.s3a.s3guard.consistency.retry.interval2s
1
(dfs.permissions.ContentSummary.subAccessfalse
*
stream.stderr.reporter.prefix	reporter:
2
)dfs.provided.aliasmap.inmemory.server.logfalse
5
,hive.llap.task.scheduler.preempt.independentfalse
6
#hive.druid.storage.storageDirectory/druid/segments
+
"hadoop.http.sni.host.check.enabledfalse
%
hive.llap.output.format.arrowtrue
2
$hive.llap.io.cvb.memory.consumption.
1073741824

hive.join.emit.interval1000
2
"yarn.resourcemanager.admin.address0.0.0.0:8033

mapreduce.job.maps2
6
+hive.llap.am.liveness.connection.timeout.ms10000ms
4
-hive.tez.dynamic.semijoin.reduction.threshold0.5
'
"dfs.provided.aliasmap.load.retries0
=
3yarn.nodemanager.node-attributes.resync-interval-ms120000

	startcode1730481641907
)
dfs.balancer.getBlocks.size
2147483648

mapreduce.am.max-attempts2
.
)dfs.balancer.service.retries.on.exception5
+
#hive.tez.dynamic.semijoin.reductiontrue

hive.prewarm.enabledfalse
,
!hive.io.rcfile.record.buffer.size4194304
9
dfs.datanode.data.dir file:///tmp/hadoop-root/dfs/data
.
&hive.tez.llap.min.reducer.per.executor0.33
,
#adl.feature.ownerandgroup.enableupnfalse
/
&datanucleus.schema.validateConstraintsfalse
$
hive.llap.io.path.cache.size10Mb
6
hive.arrow.root.allocator.limit9223372036854775807
:
3dfs.client.write.byte-array-manager.count-threshold128
S
4hive.security.authorization.createtable.owner.grantsINSERT,SELECT,UPDATE,DELETE
 
hive.optimize.topnkey.max128
s
1hive.splits.available.slots.calculator.class.name>org.apache.hadoop.hive.ql.exec.tez.TezAvailableSlotsCalculator
$
dfs.datanode.bp-ready.timeout20s
-
$yarn.nodemanager.amrmproxy.ha.enablefalse
.
)yarn.app.mapreduce.client.job.max-retries3
0
'hive.vectorized.use.checked.expressionsfalse
7
"hadoop.security.key.default.cipherAES/CTR/NoPadding
.
%yarn.resourcemanager.recovery.enabledfalse
@
6dfs.storage.policy.satisfier.self.retry.timeout.millis300000
$
hive.llap.auto.enforce.statstrue
 
hive.log.explain.outputfalse

hive.optimize.skewjoinfalse
#
hive.default.fileformatTextFile
*
"hive.llap.client.consistent.splitstrue
A
7yarn.nodemanager.node-labels.provider.fetch-interval-ms600000

fs.s3a.max.total.tasks32
!
mapreduce.reduce.maxattempts4
'
hive.optimize.filter.preds.sorttrue
.
(tez.am.minimum.allowed.speculative.tasks10
-
%hive.optimize.remove.identity.projecttrue

tez.am.view-aclsroot
A
8dfs.client.deadnode.detection.probe.deadnode.interval.ms60000
)
$yarn.nodemanager.delete.thread-count4
@
yarn.nodemanager.admin-env"MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX
"
hive.compactor.worker.threads0
%
hive.compactor.wait.timeout300000
-
(ipc.[port_number].weighted-cost.response1

hive.llap.management.acl*
+
&dfs.qjournal.parallel-read.num-threads5
2
+mapreduce.job.speculative.slowtaskthreshold1.0
4
,hive.server2.thrift.http.cookie.auth.enabledtrue
1
*hive.llap.daemon.delegation.token.lifetime14d
F
,hive.metastore.archive.intermediate.archived_INTERMEDIATE_ARCHIVED
q
Erpc.engine.org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB(org.apache.hadoop.ipc.ProtobufRpcEngine2
G
@yarn.nodemanager.default-container-executor.log-dirs.permissions710
9
1hadoop.security.dns.log-slow-lookups.threshold.ms1000
/
(hive.llap.nodehealthchecks.executorratio2.0
9
,hive.tez.bigtable.minsize.semijoin.reduction	100000000
-
(hive.localize.resource.num.wait.attempts5
4
/dfs.namenode.replication.max-streams-hard-limit4
\
#yarn.sharedcache.checksum.algo.impl5org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl
)
#hive.optimize.transform.in.maxnodes16
#
hive.limit.optimize.enablefalse
!
tez.am.resource.memory.mb1536
7
.yarn.resourcemanager.resource-profiles.enabledfalse
9
/mapreduce.output.fileoutputformat.compress.typeRECORD
b
\yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.cache-refresh-interval-secs60
6
-hive.parquet.date.proleptic.gregorian.defaultfalse
6
-yarn.nodemanager.numa-awareness.read-topologyfalse
&
!hadoop.hdfs.configuration.version1
,
#yarn.nodemanager.log.retain-seconds10800
@
7hive.test.vectorization.suppress.explain.execution.modefalse
'
 hive.llap.io.allocator.alloc.min4Kb
)
 hive.server2.saml2.sign.requestsfalse
1
)yarn.nodemanager.resource.memory.enforcedtrue
9
0ha.failover-controller.new-active.rpc-timeout.ms60000
:
(io.erasurecode.codec.rs-legacy.rawcodersrs-legacy_java
%
dfs.client.read.shortcircuitfalse
)
hive.merge.smallfiles.avgsize16000000
'
hadoop.ssl.hostname.verifierDEFAULT
8
/hive.tez.dynamic.semijoin.reduction.for.mapjoinfalse

hive.hbase.wal.enabledtrue

tez.ignore.lib.uristrue
.
&hive.server2.logging.operation.enabledtrue
,
%dfs.client.failover.sleep.base.millis500
K
Cyarn.resourcemanager.nm-container-queuing.sorting-nodes-interval-ms1000
!
hive.support.concurrencyfalse
&
fs.s3a.select.input.csv.headernone
+
"hive.orc.cache.use.soft.referencesfalse
'
"dfs.client.socket.send.buffer.size0
;
2mapreduce.fileoutputcommitter.task.cleanup.enabledfalse

hive.file.max.footer100
"
dfs.blockreport.initialDelay0s

hive.cli.print.headerfalse
6
/hive.tez.task.scale.memory.reserve.fraction.max0.5
2
*hive.optimize.metadata.query.cache.enabledtrue
!
hive.hashtable.loadfactor0.75
B
9yarn.timeline-service.entity-group-fs-store.with-user-dirfalse
-
$dfs.client.failover.sleep.max.millis15000
.
%hive.test.fail.load.dynamic.partitionfalse
C
;yarn.resourcemanager.activities-manager.cleanup-interval-ms5000
7
1hive.llap.task.communicator.listener.thread-count30
-
%hive.vectorized.complex.types.enabledtrue
#
hive.server2.wm.worker.threads4
7
0tez.runtime.task.input.post-merge.buffer.percent0.0
H
?yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs86400
"
hive.script.auto.progressfalse
0
+yarn.nodemanager.log.deletion-threads-count4
)
 ha.health-monitor.rpc-timeout.ms45000
#
hive.exec.dynamic.partitiontrue
/
)yarn.resourcemanager.application.max-tags10
0
)hive.tez.container.max.java.heap.fraction0.8
L
Dyarn.nodemanager.linux-container-executor.nonsecure-mode.limit-userstrue
4
/dfs.storage.policy.satisfier.retry.max.attempts3
%
hive.server2.wm.delayed.movefalse
C
>yarn.resourcemanager.placement-constraints.algorithm.pool-size1
$
hive.llap.daemon.umbilical.port0
,
%hive.server2.saml2.callback.token.ttl30s
Y
6yarn.timeline-service.entity-group-fs-store.active-dir/tmp/entity-file-history/active
)
!hive.optimize.reducededuplicationtrue
5
fs.s3a.impl&org.apache.hadoop.fs.s3a.S3AFileSystem
,
%hive.repl.partitions.dump.parallelism100
=
2hive.llap.daemon.am.liveness.heartbeat.interval.ms10000ms
3
*dfs.namenode.fs-limits.max-blocks-per-file10000
?
3yarn.resourcemanager.delegation.key.update-interval86400000
9
3hive.llap.io.decoding.metrics.percentiles.intervals30
5
%yarn.nodemanager.webapp.https.address0.0.0.0:8044
f
%dfs.namenode.hosts.provider.classname=org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager

#hive.security.authorization.managerZorg.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory
*
#hive.thrift.client.max.message.size1gb
&
hive.metastore.uri.selectionRANDOM
+
#dfs.namenode.lifeline.handler.ratio0.10
"
mapreduce.map.skip.maxrecords0
/
&hive.strict.checks.no.partition.filterfalse

ipc.ping.interval60000
/
*mapreduce.jobhistory.loadedjobs.cache.size5
"
dfs.storage.policy.enabledtrue
6
/yarn.resourcemanager.application.max-tag.length100
-
$hadoop.metrics.jvm.use-thread-mxbeanfalse
(
mapreduce.client.output.filterFAILED
+
"hive.mapjoin.hybridgrace.hashtablefalse
Z
hive.metastore.txn.store.impl9org.apache.hadoop.hive.metastore.txn.CompactionTxnHandler
9
3yarn.nodemanager.resource.system-reserved-memory-mb-1
%
dfs.journalnode.edits.dir.perm700
R
list.sink.output.formatter4org.apache.hadoop.hive.serde2.thrift.ThriftFormatter
&
hive.llap.object.cache.enabledtrue

hive.map.groupby.sortedtrue
2
&mapreduce.shuffle.pathcache.max-weight10485760
)
#hive.server2.idle.operation.timeout2h
#
hive.cbo.costmodel.hdfs.read1.5
9
2hive.tez.dynamic.semijoin.reduction.for.dpp.factor1.0
,
$hive.server2.parallel.ops.in.sessiontrue
%
hive.server2.transport.modebinary
+
#hive.materializedview.rewriting.sqltrue
/
&hive.compactor.delayed.cleanup.enabledfalse
-
$dfs.namenode.stale.datanode.interval30000
%
hive.stats.filter.in.min.ratio0.0
3
+ipc.[port_number].decay-scheduler.period-ms5000

tez.am.mode.sessiontrue
)
!fs.client.resolve.remote.symlinkstrue
+
"tez.runtime.merge.progress.records10000
(
 dfs.federation.router.rpc.enabletrue
D
 fs.AbstractFileSystem.wasbs.impl org.apache.hadoop.fs.azure.Wasbs
?
:yarn.resourcemanager.nm-container-queuing.min-queue-length5
2
*hive.optimize.shared.work.downstream.mergetrue
 
mapreduce.reduce.cpu.vcores1

tez.job.nameHIVE-%s

hadoop.ssl.enabledfalse
)
!hive.server2.webui.xframe.enabledtrue
9
dfs.namenode.name.dir file:///tmp/hadoop-root/dfs/name
$
hive.server2.thrift.sasl.qopauth
2
,hive.metastore.client.cache.initial.capacity50
%
hive.repl.retry.total.duration24h
'
hive.hook.proto.file.per.eventfalse
L
Cyarn.scheduler.configuration.leveldb-store.compaction-interval-secs86400
/
)mapreduce.task.local-fs.write-limit.bytes-1
H
:yarn.resourcemanager.configuration.file-system-based-store
/yarn/conf
(
"hive.compactor.delta.num.threshold10
&
dfs.block.access.token.enablefalse
+
#hive.llap.daemon.web.xframe.enabledtrue
A
'dfs.webhdfs.rest-csrf.methods-to-ignoreGET,OPTIONS,HEAD,TRACE
+
%dfs.namenode.reencrypt.sleep.interval1m

adl.http.timeout-1

tez.task.timeout-ms600000
4
+dfs.client.write.byte-array-manager.enabledfalse
$
dfs.namenode.storage.dir.perm700
6
1dfs.datanode.fileio.profiling.sampling.percentage0
'
 hive.map.aggr.hash.percentmemory0.5
3
&hive.metastore.server.max.message.size	104857600
/
'hive.exec.job.debug.capture.stacktracestrue
*
tez.job.fs-servershdfs://namenode:8020
6
"hive.service.metrics.file.location/tmp/report.json
(
"hadoop.security.kms.client.timeout60
'
hive.stats.ndv.estimate.percent20.0
C
:dfs.short.circuit.shared.memory.watcher.interrupt.check.ms60000

hive.sample.seednumber0
F
>yarn.resourcemanager.reservation-system.planfollower.time-step1000
;
3yarn.resourcemanager.ha.automatic-failover.embeddedtrue
 
dfs.datanode.handler.count10
?
'hive.server2.webui.cors.allowed.methodsGET,POST,DELETE,HEAD
-
%hive.optimize.joinreducededuplicationtrue
7
.hive.mapred.reduce.tasks.speculative.executionfalse
3
+hive.tez.dynamic.partition.pruning.extendedtrue
,
%hive.vectorized.groupby.flush.percent0.1
$
hive.stats.estimators.enabletrue
E
=dfs.namenode.block-placement-policy.default.prefer-local-nodetrue
2
-dfs.namenode.resource.checked.volumes.minimum1
A
8dfs.client.block.write.locateFollowingBlock.max.delay.ms60000
2
*hive.optimize.bi.rewrite.cume_dist.enabledtrue
(
"dfs.http.client.retry.max.attempts10
.
)hive.llap.daemon.num.file.cleaner.threads1
K
Dyarn.resourcemanager.nodemanagers.heartbeat-interval-slowdown-factor1.0

hive.in.repl.testfalse
/
yarn.resourcemanager.keytab/etc/krb5.keytab
7
+yarn.nodemanager.runtime.linux.sandbox-modedisabled
,
#hive.metastore.client.cache.enabledfalse
?
8hive.scheduled.queries.executor.progress.report.interval60s
!
hive.exec.submitviachildfalse
R
*fs.viewfs.overload.scheme.target.file.impl$org.apache.hadoop.fs.LocalFileSystem
1
'yarn.log-aggregation-status.time-out.ms600000
3
*hive.blobstore.use.blobstore.as.scratchdirfalse
s
!yarn.federation.state-store.classNorg.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore
0
+yarn.client.max-cached-nodemanagers-proxies0
g
"yarn.sharedcache.app-checker.classAorg.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker
-
$dfs.namenode.retrycache.heap.percent0.03f

hive.execution.enginetez
.
%hive.test.vectorized.adaptor.overridefalse
(
 hive.llap.io.allocator.mmap.path/tmp

hive.tez.container.size-1
9
4dfs.image.transfer-bootstrap-standby.bandwidthPerSec0
4
-ipc.[port_number].weighted-cost.lockexclusive100
4
-dfs.namenode.max-corrupt-file-blocks-returned100
$
dfs.balancer.block-move.timeout0
)
$yarn.resourcemanager.am.max-attempts2

&dfs.federation.router.store.serializerUorg.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializerPBImpl
#
hive.compactor.max.num.delta500

hive.optimize.null.scantrue
<
5yarn.timeline-service.client.internal-timers-ttl-secs420
.
'dfs.federation.router.reader.queue.size100
/
&dfs.block.scanner.skip.recent.accessedfalse
&
hive.test.acid.key.index.skipfalse
%
fs.s3a.awsSecretAccessKeydatalake
+
%yarn.app.attempt.diagnostics.limit.kc64
#
hive.stats.fetch.bitvectorfalse
c
hive.query.stringNselect+count%28*%29+from+busdata.bus_positions+where+data+%3D+%272024-11-01%27
+
$dfs.namenode.checkpoint.check.period60s
-
$hive.auto.convert.join.use.nonstagedfalse
,
$dfs.datanode.lock.read.write.enabledtrue
*
"dfs.namenode.max-num-blocks-to-log1000
?
6dfs.datanode.ec.reconstruction.stripedread.buffer.size65536
?
9hadoop.security.group.mapping.ldap.search.attr.group.namecn
)
!dfs.federation.router.http.enabletrue
,
'dfs.namenode.max.slowpeer.collect.nodes5
(
"dfs.namenode.service.handler.count10
1
)hive.server2.idle.session.check.operationtrue
5
-hive.disable.unsafe.external.table.operationstrue
_
.fs.viewfs.overload.scheme.target.swebhdfs.impl-org.apache.hadoop.hdfs.web.SWebHdfsFileSystem
)
#yarn.router.pipeline.cache-max-size25
+
#hive.metastore.server.tcp.keepalivetrue
4
+hive.materializedview.rewriting.incrementalfalse
&
!hive.io.rcfile.column.number.conf0
7
,hive.server2.materializedviews.registry.implDEFAULT
)
 hive.zookeeper.clean.extra.nodesfalse
&
hive.llap.io.etl.skip.formatencode
#
hive.optimize.metadataonlyfalse
7
2hive.llap.daemon.output.service.max.pending.writes8
0
*hadoop.security.groups.negative-cache.secs30
Z
_hive.hdfs.session.path?/opt/hive/scratch_dir/root/00f712e8-ce88-47df-9938-d3857344e739
@
9yarn.client.nodemanager-client-async.thread-pool-max-size500
5
-hive.metastore.event.db.notification.api.authtrue

tez.local.modetrue
<
4yarn.minicluster.yarn.nodemanager.resource.memory-mb4096
(
#dfs.namenode.checkpoint.max-retries3
<
3hive.exec.orc.delta.streaming.optimizations.enabledfalse
%
ftp.client-write-packet-size65536
0
yarn.timeline-service.keytab/etc/krb5.keytab
4
+hive.auto.convert.sortmerge.join.to.mapjoinfalse

hive.fetch.task.aggrfalse
%
hive.optimize.limittransposefalse
!
hive.llap.io.memory.modecache
9
1hive.optimize.shared.work.dppunion.merge.eventopstrue
(
ha.zookeeper.session-timeout.ms10000
#
hive.cbo.returnpath.hiveopfalse
,
%hadoop.security.key.default.bitlength128
'
dfs.datanode.fixed.volume.sizefalse
B
;dfs.client.deadnode.detection.probe.suspectnode.interval.ms300

hive.stats.ndv.algohll
&
hive.server2.webui.use.spnegofalse
€
'yarn.node-attribute.fs-store.impl.classUorg.apache.hadoop.yarn.server.resourcemanager.nodelabels.FileSystemNodeAttributeStore

hive.stats.udtf.factor1.0
2
(dfs.datanode.cache.revocation.timeout.ms900000
-
$yarn.nodemanager.recovery.supervisedfalse
0
'mapreduce.task.combine.progress.records10000
-
#hive.service.metrics.file.frequency5000ms

hive.optimize.ppdtrue
%
hive.exec.script.maxerrsize100000
<
5hive.llap.task.scheduler.am.collect.daemon.metrics.ms0ms
7
hive.session.id$00f712e8-ce88-47df-9938-d3857344e739
0
(hive.auto.convert.join.noconditionaltasktrue
%
hive.stats.fetch.column.statstrue
'
hive.stats.filter.range.uniformtrue
(
hive.skewjoin.mapjoin.map.tasks10000
)
!hive.llap.hs2.coordinator.enabledtrue

tez.am.resource.cpu.vcores1
.
(dfs.federation.router.client.thread-size32
'
"hive.msck.repair.batch.max.retries4
2
$yarn.scheduler.queue-placement-rules
user-group
A
5hadoop.security.kms.client.encrypted.key.cache.expiry43200000
-
$hive.repl.load.partitions.batch.size10000
!
yarn.sharedcache.enabledfalse
$
hive.compactor.initiator.onfalse
W
hive.metastore.fs.handler.class4org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl
z
(hive.security.authorization.task.factoryNorg.apache.hadoop.hive.ql.parse.authorization.HiveAuthorizationTaskFactoryImpl
1
,yarn.router.interceptor.user.threadpool-size5
%
fs.azure.user.agent.prefixunknown
&
hive.optimize.distinct.rewritetrue
'
"dfs.datanode.directoryscan.threads1
)
 fs.s3a.delegation.tokens.enabledfalse
8
1dfs.federation.router.quota-cache.update.interval60s
#
hive.exec.orc.base.delta.ratio8
 
hive.metastore.fastpathfalse
<
4ha.failover-controller.graceful-fence.rpc-timeout.ms5000
e
5hive.optimize.update.table.properties.from.serde.list,org.apache.hadoop.hive.serde2.avro.AvroSerDe
1
 dfs.namenode.backup.http-address0.0.0.0:50105
D
;yarn.resourcemanager.application-tag-based-placement.enablefalse
'
hive.zookeeper.killquery.enabletrue
7
.yarn.resourcemanager.reservation-system.enablefalse
*
"hadoop.security.crypto.buffer.size8192

hadoop.registry.securefalse
*
$hive.llap.file.cleanup.delay.seconds0s
!
hive.optimize.ppd.storagetrue
&
hive.llap.management.rpc.port15004
(
#dfs.namenode.safemode.min.datanodes0
+
$hive.txn.acid.metrics.max.cache.size100
'
 hive.cbo.costmodel.local.fs.read4.0
O
Fdfs.namenode.available-space-block-placement-policy.balance-local-nodefalse
,
$hive.mapjoin.hybridgrace.bloomfiltertrue
&
dfs.webhdfs.socket.read-timeout60s
4
-hive.metastore.aggregate.stats.cache.max.full0.9
,
#hive.security.authorization.enabledfalse
0
'dfs.namenode.avoid.write.stale.datanodefalse
'
yarn.resourcemanager.fail-fastfalse
L
2yarn.resourcemanager.resource-profiles.source-fileresource-profiles.json
4
hive.user.install.directory/opt/hive/install_dir
,
'ipc.[port_number].weighted-cost.handler1
(
 hive.insert.into.external.tablestrue
L
Cyarn.nodemanager.runtime.linux.docker.privileged-containers.allowedfalse
6
.yarn.timeline-service.client.retry-interval-ms1000
"
mapreduce.shuffle.max.threads0
)
 hive.zookeeper.ssl.client.enablefalse
0
)hive.compactor.aborted.txn.time.threshold12h
)
$dfs.ha.tail-edits.period.backoff-max0

io.file.buffer.size4096
'
dfs.ha.zkfc.nn.http.timeout.ms20000
.
%dfs.client.deadnode.detection.enabledfalse
?
6yarn.nodemanager.container-metrics.unregister-delay-ms10000
"
hive.lock.file.move.protectall

hive.jobname.length50
9
dfs.journalnode.edits.dir/tmp/hadoop/dfs/journalnode/
)
 hive.acid.lockless.reads.enabledfalse
O
'yarn.resourcemanager.fs.state-store.uri$/tmp/hadoop-root/yarn/system/rmstore
>
6yarn.timeline-service.client.drain-entities.timeout.ms2000
'
!hive.server2.webui.max.graph.size25
)
#hive.llap.plugin.client.num.threads10
>
fs.AbstractFileSystem.adl.implorg.apache.hadoop.fs.adl.Adl
1
(hadoop.registry.zk.connection.timeout.ms15000
B
fs.AbstractFileSystem.wasb.implorg.apache.hadoop.fs.azure.Wasb
2
+dfs.datanode.ec.reconstruction.xmits.weight0.5
%
dfs.cachereport.intervalMsec10000
)
#dfs.ha.tail-edits.rolledits.timeout60
,
'hive.compactor.history.retention.failed3
1
,yarn.app.mapreduce.am.container.log.limit.kb0
.
)dfs.federation.router.admin.handler.count1
8
0yarn.nodemanager.resourcemanager.minimum.versionNONE
"
hive.test.bucketcodec.version1
I
hive.query.id8root_20241101180712_0964671c-f723-4c65-b7ad-9bdb211e3a9b
&
hive.transactional.table.scanfalse
&
!mapreduce.job.ubertask.maxreduces1
(
"dfs.image.parallel.target.sections12
E
@hadoop.security.group.mapping.ldap.search.group.hierarchy.levels0
(
 hive.txn.write.acid.version.filetrue
%
hive.stats.max.variable.length100

ftp.stream-buffer-size4096
7
2dfs.client.failover.connection.retries.on.timeouts0

tez.runtime.compressfalse

fs.ftp.timeout0
,
$hive.exec.rcfile.use.explicit.headertrue
;
3hadoop.http.authentication.simple.anonymous.allowedtrue
3
+hive.materializedview.rewriting.time.window0min
&
hive.query.reexecution.enabledtrue
:
1yarn.client.nodemanager-connect.retry-interval-ms10000
1
'hive.zookeeper.connection.basesleeptime1000ms
I
<yarn.timeline-service.leveldb-timeline-store.read-cache-size	104857600
(
hadoop.security.authenticationsimple
I
dfs.image.compression.codec*org.apache.hadoop.io.compress.DefaultCodec
2
)mapreduce.task.files.preserve.failedtasksfalse
[
Nyarn.timeline-service.hbase.coprocessor.app-final-value-retention-milliseconds	259200000
3
-hive.query.reexecution.stats.cache.batch.size-1
#
hive.optimize.point.lookup.min2
2
(dfs.qjournal.finalize-segment.timeout.ms120000
4
.yarn.nodemanager.amrmproxy.client.thread-count25
0
'mapreduce.jobhistory.joblist.cache.size20000
h
8dfs.federation.router.kerberos.internal.spnego.principal,${dfs.web.authentication.kerberos.principal}
=
7yarn.nodemanager.runtime.linux.docker.stop.grace-period10
1
+dfs.namenode.fs-limits.max-xattrs-per-inode32

hive.conf.validationtrue
:
hive.script.operator.id.env.varHIVE_SCRIPT_OPERATOR_ID
4
.dfs.namenode.gc.time.monitor.sleep.interval.ms5s
/
(hive.compactor.small.delta.dir.threshold200
&
javax.jdo.option.Multithreadedtrue
,
!tez.runtime.ifile.readahead.bytes4194304

fs.s3a.multipart.purgefalse
%
fs.getspaceused.jitterMillis60000
i
9dfs.secondary.namenode.kerberos.internal.spnego.principal,${dfs.web.authentication.kerberos.principal}
?
6yarn.rm.system-metrics-publisher.emit-container-eventsfalse
(
dfs.namenode.snapshot.max.limit65536
7
.dfs.namenode.invalidate.work.pct.per.iteration0.32f
6
.hive.optimize.bi.rewrite.countdistinct.enabledtrue
V
'hive.server2.webui.cors.allowed.headers+X-Requested-With,Content-Type,Accept,Origin
>
9hive.llap.daemon.metrics.timed.window.average.data.points0
Y
/yarn.scheduler.configuration.leveldb-store.path&/tmp/hadoop-root/yarn/system/confstore
/
(dfs.federation.router.handler.queue.size100
6
-yarn.resourcemanager.webapp.rest-csrf.enabledfalse

hive.exec.reducers.max1009
4
-hive.llap.daemon.service.refresh.interval.sec60s
<
3hive.avro.timestamp.write.legacy.conversion.enabledfalse
2
$hive.fetch.task.conversion.threshold
1073741824
)
hadoop.http.authentication.typesimple
7
0dfs.namenode.list.encryption.zones.num.responses100
,
hive.llap.auto.max.output.size
1073741824
0
'yarn.nodemanager.numa-awareness.enabledfalse

mapreduce.map.cpu.vcores1
)
"dfs.namenode.decommission.interval30s
*
!hive.script.operator.truncate.envfalse
!
hive.join.inner.residualfalse
m
fyarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-timeout-interval-secs360
8
3yarn.nodemanager.elastic-memory-control.timeout-sec5
+
#yarn.nodemanager.pmem-check-enabledtrue
0
+ipc.[port_number].scheduler.priority.levels4
/
'dfs.namenode.inotify.max.events.per.rpc1000
.
%hive.server2.active.passive.ha.enablefalse
'
tez.runtime.shuffle.ssl.enablefalse
/
'hive.llap.remote.token.requires.signingtrue
A
fs.abfs.impl1org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem

hive.tez.bucket.pruningtrue
'
hive.llap.io.trace.always.dumpfalse
#
hive.llap.hdfs.package.dir.yarn
7
*hive.query.reexecution.stats.persist.scope	metastore
'
 hive.hash.table.inflation.factor2.0
2
,yarn.resourcemanager.amlauncher.thread-count50
M
Gyarn.timeline-service.timeline-client.number-of-async-entities-to-merge10

hive.txn.xlock.ctastrue
)
$dfs.provided.aliasmap.text.delimiter,
5
/yarn.sharedcache.nm.uploader.replication.factor10
)
"dfs.lock.suppress.warning.interval10s
!
hive.ctas.external.tablestrue
'
hive.exec.local.scratchdir	/tmp/root
2
+yarn.timeline-service.client.fd-retain-secs300
#
hive.stats.gather.num.threads10
%
hadoop.caller.context.max.size128
(
 hadoop.http.cross-origin.max-age1800
 
hive.mm.allow.originalsfalse
5
mapreduce.jobhistory.principaljhs/_HOST@REALM.TLD
,
$dfs.federation.router.metrics.enabletrue
5
(hive.exec.mode.local.auto.inputbytes.max	134217728
1
)hive.optimize.shared.work.merge.ts.schematrue
)
!hive.llap.auto.enforce.vectorizedtrue
.
'hive.mapjoin.localtask.max.memory.usage0.9
$
hive.writeset.reaper.interval60s
0
(hive.scheduled.queries.create.as.enabledtrue
m
dfs.provided.aliasmap.classNorg.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap
6
.hive.internal.ss.authz.settings.applied.markertrue
(
!fs.s3a.metadatastore.metadata.ttl15m
*
"hive.compactor.compact.insert.onlytrue
&
hive.hbase.snapshot.restoredir/tmp
"
hive.order.columnalignmenttrue
:
0hive.llap.daemon.output.service.send.buffer.size131072
<
3hive.metastore.aggregate.stats.cache.max.partitions10000
*
%dfs.namenode.num.checkpoints.retained2
,
mapreduce.jobhistory.max-age-ms	604800000

fs.azure.authorizationfalse
+
%hive.new.job.grouping.set.cardinality30
,
#hive.enforce.sortmergebucketmapjoinfalse
 
hive.tez.smb.number.waves0.5
>
4hive.metastore.aggregate.stats.cache.max.writer.wait5000ms
,
$hive.repl.ranger.client.read.timeout300s
*
$hive.server2.llap.concurrent.queries-1
&
hive.avro.proleptic.gregorianfalse
"
hive.llap.auto.allow.uberfalse
4
)dfs.block.scanner.volume.bytes.per.second1048576
=
5hive.load.dynamic.partitions.scan.specific.partitionstrue
-
$fs.s3a.s3guard.ddb.table.sse.enabledfalse
3
(dfs.client.read.shortcircuit.buffer.size1048576

ipc.client.rpc-timeout.ms0
A
9dfs.datanode.ec.reconstruction.stripedread.timeout.millis5000
.
&hive.write.notification.max.batch.size1000
[
hive.repl.task.factoryAorg.apache.hive.hcatalog.api.repl.exim.EximReplicationTaskFactory
1
(hive.int.timestamp.conversion.in.secondsfalse

hive.txn.xlock.iowtrue
*
!hive.tez.auto.reducer.parallelismfalse
L
hive.metastore.rawstore.impl,org.apache.hadoop.hive.metastore.ObjectStore
&
!dfs.disk.balancer.max.disk.errors5
j
mapreduce.task.profile.paramsI-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s

fs.s3a.committer.namefile
‹
-hive.security.metastore.authorization.managerZorg.apache.hadoop.hive.ql.security.authorization.DefaultHiveMetastoreAuthorizationProvider
 
dfs.namenode.handler.count10
&
hive.orc.splits.include.fileidtrue
.
"dfs.image.transfer.bandwidthPerSec52428800
/
)hive.llap.daemon.communicator.num.threads10
#
hive.orderby.position.aliastrue
m
)yarn.client.failover-no-ha-proxy-provider@org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider
'
hive.lineage.hook.info.enabledfalse
!
yarn.node-labels.enabledfalse
0
*yarn.timeline-service.handler-thread-count10

fs.s3a.threads.max64
I
?hive.llap.task.communicator.connection.sleep.between.retries.ms2000ms
2
(yarn.resourcemanager.connect.max-wait.ms900000
G
>hive.vectorized.execution.mapjoin.native.multikey.only.enabledfalse
'
hive.in.repl.test.files.sortedfalse
'
!mapreduce.job.max.split.locations15
.
&hive.service.metrics.hadoop2.componenthive

dfs.blocksize	134217728
7
.mapreduce.shuffle.connection-keep-alive.enablefalse
"
fs.s3a.threads.keepalivetime60
1
$hive.server2.logging.operation.level	EXECUTION
%
datanucleus.cache.level2.typenone
(
yarn.nodemanager.disk-validatorbasic
2
,hadoop.security.groups.shell.command.timeout0s
)
$hive.metastore.direct.sql.batch.size0
&
ha.zookeeper.aclworld:anyone:rwcda
.
&hive.direct.sql.max.elements.in.clause1000
/
'dfs.namenode.write.stale.datanode.ratio0.5f
!
hive.test.load.utilization0.2
:
)dfs.datanode.shared.file.descriptor.paths/dev/shm,/tmp
3
-dfs.federation.router.store.router.expiration5m
0
+mapreduce.input.lineinputformat.linespermap1
0
)dfs.provided.aliasmap.inmemory.batch-size500
2
-yarn.nodemanager.localizer.fetch.thread-count4
4
,hive.llap.cache.defaultfs.only.native.fileidtrue
1
)hive.server2.saml2.want.assertions.signedtrue
9
0hive.repl.ha.datapath.replace.remote.nameservicefalse
T
Aipc.[port_number].decay-scheduler.backoff.responsetime.thresholds10s,20s,30s,40s

hive.stats.autogathertrue
/
)dfs.client.deadnode.detection.rpc.threads20
3
*dfs.client.read.shortcircuit.skip.checksumfalse
B
9yarn.resourcemanager.delegation-token.max-conf-size-bytes12800
%
dfs.namenode.quota.init-threads12
.
'hive.druid.indexer.segments.granularityDAY
1
*dfs.datanode.metrics.logger.period.seconds600
5
-hive.server2.thrift.http.response.header.size6144
<
6yarn.nodemanager.log-aggregation.num-log-files-per-app30
g
 hive.conf.internal.variable.listChive.added.files.path,hive.added.jars.path,hive.added.archives.path
H
Byarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size10
-
$tez.am.soonest.retry.after.speculate15000
"
hive.llap.kerberos.enabledtrue
8
1hive.server2.operation.log.purgePolicy.timeToLive60s
 
hive.testing.remove.logstrue
-
!datanucleus.connectionPoolingTypeHikariCP
o
 hive.metastore.cache.pinobjtypesKTable,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order
7
0hive.optimize.limittranspose.reductionpercentage1.0
!
dfs.balancer.address	0.0.0.0:0
_
*fs.viewfs.overload.scheme.target.abfs.impl1org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem
#
hive.distcp.privileged.doAshive
,
#hive.strict.checks.orderby.no.limitfalse
"
mapred.input.dir.recursivetrue
"
fs.s3a.multipart.threshold128M
1
(yarn.scheduler.include-port-in-node-namefalse
1
)hive.cbo.stats.correlated.multi.key.joinstrue
0
(hive.metastore.aggregate.stats.cache.ttl600s
_
/dfs.namenode.kerberos.internal.spnego.principal,${dfs.web.authentication.kerberos.principal}
8
3yarn.nodemanager.resource.memory.cgroups.swappiness0
%
dfs.datanode.dns.interfacedefault
'
"hive.orc.splits.directory.batch.ms0
:
1dfs.encrypt.data.overwrite.downstream.derived.qopfalse
&
fs.s3a.change.detection.modeserver
7
,yarn.resourcemanager.zk-max-znode-size.bytes1048576
#
dfs.datanode.max.locked.memory0
4
+dfs.federation.router.store.connection.test60000
+
"dfs.ha.fencing.ssh.connect-timeout30000
G
>dfs.client.block.write.replace-datanode-on-failure.best-effortfalse
/
'hive.metastore.client.cache.expiry.time120s
Y
hive.lock.managerDorg.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager
'
hive.tez.exec.inplace.progressfalse
&
dfs.webhdfs.rest-csrf.enabledfalse
(
dfs.datanode.ipc.address0.0.0.0:9867
4
+hive.mapper.cannot.span.multiple.partitionsfalse
2
)dfs.block.misreplication.processing.limit10000
8
/dfs.namenode.path.based.cache.retry.interval.ms30000
D
9dfs.client.block.write.replace-datanode-on-failure.policyDEFAULT
%
 fs.s3a.fast.upload.active.blocks4
(
hive.lock.mapred.only.operationfalse
(
yarn.resourcemanager.hostname0.0.0.0
&
hadoop.registry.jaas.contextClient
%
hive.tez.min.partition.factor0.25
M
6hadoop.security.group.mapping.ldap.search.filter.group(objectClass=group)
1
*hadoop.shell.safely.delete.limit.num.files100
.
%hive.async.cleanup.service.queue.size10000
3
.dfs.namenode.storageinfo.defragment.timeout.ms4
*
"dfs.federation.router.store.enabletrue
!
dfs.client.short.circuit.num1
4
/yarn.client.failover-retries-on-socket-timeouts0
<
7mapreduce.shuffle.pathcache.expire-after-access-minutes5
$
hive.cbo.costmodel.extendedfalse
-
&hive.llap.io.allocator.defrag.headroom1Mb
0
'hive.optimize.bucketmapjoin.sortedmergefalse
a
0mapreduce.jobhistory.recovery.store.leveldb.path-/tmp/hadoop-root/mapred/history/recoverystore
=
4yarn.nodemanager.windows-container.cpu-limit.enabledfalse
S
)fs.viewfs.overload.scheme.target.ftp.impl&org.apache.hadoop.fs.ftp.FTPFileSystem
x
!hive.notification.event.consumersSorg.apache.hadoop.hive.ql.cache.results.QueryResultsCache$InvalidationEventConsumer
.
&hive.server2.zookeeper.publish.configstrue
+
#dfs.datanode.socket.reuse.keepalive4000
F
=ipc.[port_number].decay-scheduler.backoff.responsetime.enablefalse
'
 yarn.nodemanager.vmem-pmem-ratio2.1
'
dfs.namenode.checkpoint.period3600s
)
 datanucleus.schema.autoCreateAllfalse
A
6yarn.nodemanager.node-labels.provider.fetch-timeout-ms1200000
(
 hive.auto.convert.sortmerge.jointrue
v
9yarn.timeline-service.hbase.coprocessor.jar.hdfs.location9/hbase/coprocessor/hadoop-yarn-server-timelineservice.jar
8
,hive.auto.convert.join.hashtable.max.entries21000000
,
&hive.server2.tez.sessions.init.threads16
6
!io.erasurecode.codec.rs.rawcodersrs_native,rs_java
E
=hive.metastore.authorization.storage.check.externaltable.droptrue
J
Byarn.nodemanager.runtime.linux.docker.enable-userremapping.allowedtrue
J
Cyarn.resourcemanager.delegation-token-renewer.thread-retry-interval60s
I
Ayarn.resourcemanager.leveldb-state-store.compaction-interval-secs3600
E
?yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size10
#
dfs.client.https.need-authfalse
;
-hive.vectorized.input.format.supports.enabled
decimal_64
%
hive.merge.rcfile.block.leveltrue
F
Ayarn.nodemanager.runtime.linux.docker.userremapping-gid-threshold1
 
hive.execution.mode	container

fs.ftp.host.port21
F
<yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms300000
:
/yarn.nodemanager.runtime.linux.allowed-runtimesdefault
.
(hive.metastore.client.cache.max.capacity50
'
mapreduce.cluster.acls.enabledfalse
>
7mapreduce.job.encrypted-intermediate-data-key-size-bits128
(
hive.compactor.crud.query.basedfalse
 
hive.hook.proto.events.ttl7d
'
hive.materializedview.rewritingtrue
5
/yarn.nodemanager.container-manager.thread-count20
,
$dfs.namenode.redundancy.considerLoadtrue
)
!dfs.client.socketcache.expiryMsec3000
!
hive.compactor.request.queue1
0
'mapreduce.app-submission.cross-platformfalse
+
"fs.s3a.metadatastore.authoritativefalse
 
dfs.image.parallel.loadfalse
,
'mapreduce.job.reducer.preempt.delay.sec0
?
7dfs.datanode.peer.metrics.min.outlier.detection.samples1000
B
:dfs.namenode.path.based.cache.block.map.allocation.percent0.25
$
hive.server2.wm.namespacedefault
,
'dfs.datanode.data.write.bandwidthPerSec0
=
fs.har.impl.org.apache.hadoop.hive.shims.HiveHarFileSystem
!
dfs.webhdfs.use.ipc.callqtrue
9
1hive.metastore.aggregate.stats.cache.max.variance0.01
{
=yarn.timeline-service.entity-group-fs-store.cache-store-class:org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore
/
(dfs.datanode.cache.revocation.polling.ms500
0
)mapreduce.reduce.markreset.buffer.percent0.0

tez.runtime.io.sort.mb100
[
*mapreduce.jobhistory.recovery.store.fs.uri-/tmp/hadoop-root/mapred/history/recoverystore
0
+dfs.namenode.blockreport.max.lock.hold.time4

hive.cbo.show.warningstrue
,
$hadoop.registry.zk.retry.interval.ms1000
ô
"hive.metastore.client.capabilitiesÍEXTWRITE,EXTREAD,HIVEBUCKET2,HIVEFULLACIDREAD,HIVEFULLACIDWRITE,HIVECACHEINVALIDATE,HIVEMANAGESTATS,HIVEMANAGEDINSERTWRITE,HIVEMANAGEDINSERTREAD,HIVESQL,HIVEMQT,HIVEONLYMQTWRITE,ACCEPTS_UNMODIFIED_METADATA
9
0dfs.federation.router.mount-table.max-cache-size10000
&
 hive.metastore.fshandler.threads15
"
dfs.mover.movedWinWidth5400000

datanode.https.port50475
7
-dfs.datanode.cached-dfsused.check.interval.ms600000
,
'yarn.nodemanager.delete.debug-delay-sec0
&
hive.compute.query.using.statstrue
2
,hive.llap.max.concurrent.requests.per.daemon12

fs.trash.interval0

dfs.mover.moverThreads1000

mapreduce.job.name 
0
(fs.s3a.change.detection.version.requiredtrue
.
!hive.tez.max.bloom.filter.entries	100000000
F
dfs.net.topology.impl-org.apache.hadoop.hdfs.net.DFSNetworkTopology
-
(fs.s3a.select.output.csv.field.delimiter,
B
:mapreduce.job.local-fs.single-disk-limit.check.interval-ms5000

seq.io.sort.mb100
H
hive.materializedview.serde)org.apache.hadoop.hive.ql.io.orc.OrcSerde
.
&hive.metastore.client.cache.v2.enabledtrue

	nfs.rtmax1048576
6
.hive.llap.nodehealthchecks.minintervalduration300s
?
6hive.parquet.timestamp.write.legacy.conversion.enabledfalse
,
dfs.namenode.backup.address0.0.0.0:50100
E
;yarn.resourcemanager.container.liveness-monitor.interval-ms600000
)
 dfs.client.failover.random.orderfalse
'
dfs.datanode.readahead.bytes4194304
/
)dfs.federation.router.safemode.expiration3m
1
(hive.llap.external.client.cloud.rpc.port30004
5
/hive.llap.daemon.task.scheduler.wait.queue.size10
+
#mapreduce.jobhistory.cleaner.enabletrue
K
7mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignoreGET,OPTIONS,HEAD
0
&fs.s3a.committer.staging.conflict-modeappend
%
hive.exec.max.created.files100000
1
(hive.repl.include.authorization.metadatafalse

hive.cli.prompthive
;
3mapreduce.input.fileinputformat.input.dir.recursivetrue
3
+yarn.nodemanager.disk-health-checker.enabletrue
2
*yarn.nodemanager.container-monitor.enabledtrue
8
,hadoop.security.java.secure.random.algorithmSHA1PRNG
-
"dfs.image.parallel.inode.threshold1000000
&
dfs.datanode.dns.nameserverdefault

yarn.fail-fastfalse
¤
:yarn.resourcemanager.placement-constraints.algorithm.classforg.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.DefaultPlacementAlgorithm
E
;dfs.client.write.exclude.nodes.cache.expiry.interval.millis600000
+
 dfs.client.mmap.cache.timeout.ms3600000
:
3dfs.namenode.reencrypt.throttle.limit.handler.ratio1.0
2
-dfs.namenode.file.close.num-committed-allowed0
.
&hive.llap.io.nonvector.wrapper.enabledtrue

yarn.acl.enablefalse
.
&yarn.nodemanager.emit-container-eventstrue
$
hive.exim.strict.repl.tablestrue
%
hive.stats.collect.tablekeysfalse
,
'hive.optimize.cte.materialize.threshold3
/
(hive.server2.async.exec.shutdown.timeout10s
*
"hive.querylog.enable.plan.progresstrue
8
1yarn.timeline-service.writer.async.queue.capacity100
@
:yarn.resourcemanager.delegation-token-renewer.thread-count50
/
"hive.llap.cache.hydration.save.dir	/tmp/hive
9
"io.erasurecode.codec.xor.rawcodersxor_native,xor_java
E
=yarn.resourcemanager.application-timeouts.monitor.interval-ms3000
,
#hadoop.common.configuration.version3.0.0
)
!hive.optimize.semijoin.conversiontrue
-
$dfs.datanode.drop.cache.behind.readsfalse
$
hive.stats.collect.scancolsfalse
„
4dfs.federation.router.namenode.resolver.client.classLorg.apache.hadoop.hdfs.server.federation.resolver.MembershipNamenodeResolver

hive.metastore.port9083
3
+hive.server2.thrift.http.cookie.is.httponlytrue
s
Eyarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern*^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$
.
hive.metastore.uristhrift://metastore:9083
7
/yarn.resourcemanager.max-completed-applications1000
4
!yarn.federation.registry.base-diryarnfederation/

dfs.xframe.value
SAMEORIGIN
$
hive.repl.parallel.copy.tasks100
/
$hive.querylog.plan.progress.interval60000ms
F
=yarn.nodemanager.runtime.linux.docker.delayed-removal.allowedfalse

mapreduce.job.acl-view-job 
I
Adfs.namenode.decommission.backoff.monitor.pending.blocks.per.lock1000
'
hive.metastore.metrics.enabledfalse
:
0dfs.namenode.edit.log.autoroll.check.interval.ms300000
/
'mapreduce.map.skip.proc-count.auto-incrtrue
"
hive.zookeeper.client.port2181
1
'hive.server2.thrift.http.cookie.max.age86400s
?
5hadoop.security.group.mapping.ldap.search.attr.membermember
6
-hive.repl.external.warehouse.single.copy.taskfalse
(
hadoop.ssl.client.confssl-client.xml
-
dfs.journalnode.https-address0.0.0.0:8481
3
+tez.shuffle-vertex-manager.min-src-fraction0.05
<
4dfs.datanode.directoryscan.throttle.limit.ms.per.sec1000
(
hive.llap.daemon.loggerquery-routing
%
dfs.image.transfer.chunksize65536
#
hive.server2.webui.use.pamfalse
7
.yarn.resourcemanager.connect.retry-interval.ms30000
4
"dfs.client.https.keystore.resourcessl-client.xml
4
$yarn.timeline-service.webapp.address0.0.0.0:8188
/
&hive.ptf.valuecache.collect.statisticsfalse
/
*yarn.sharedcache.cleaner.resource-sleep-ms0
(
io.seqfile.compress.blocksize1000000
)
#dfs.federation.router.handler.count10
N
!dfs.namenode.checkpoint.edits.dir)file:///tmp/hadoop-root/dfs/namesecondary
P
!dfs.client.failover.resolver.impl+org.apache.hadoop.net.DNSDomainNameResolver
%
 hive.query.reexecution.max.count1
(
hive.llap.io.share.object.poolsfalse
9
0hive.optimize.update.table.properties.from.serdefalse
¼
.hive.service.metrics.codahale.reporter.classes‰org.apache.hadoop.hive.common.metrics.metrics2.JsonFileMetricsReporter, org.apache.hadoop.hive.common.metrics.metrics2.JmxMetricsReporter
&
tez.runtime.sort.spill.percent0.80
"
hive.cli.tez.session.asynctrue
*
hive.server2.table.type.mappingCLASSIC
(
dfs.namenode.safemode.extension30000
5
+hive.metastore.event.db.listener.timetolive86400s
e
2mapreduce.job.reduce.shuffle.consumer.plugin.class/org.apache.hadoop.mapreduce.task.reduce.Shuffle
>
3ipc.[port_number].faircallqueue.multiplexer.weights8,4,2,1
#
hive.optimize.union.removefalse
6
/hive.compactor.cleaner.duration.update.interval60s
#
hadoop.http.staticuser.userroot

fs.s3a.list.version2
-
%hive.tez.session.events.print.summarynone
@
4yarn.resourcemanager.delegation.token.renew-interval86400000
1
)hive.analyze.stmt.collect.partlevel.statstrue
M
 ipc.[port_number].scheduler.impl)org.apache.hadoop.ipc.DefaultRpcScheduler
A
*hadoop.http.authentication.kerberos.keytab/root/hadoop.keytab
6
.fs.azure.saskey.usecontainersaskeyforallaccesstrue
8
/hive.security.hbase.urlencode.authorization.urifalse
H
dfs.namenode.checkpoint.dir)file:///tmp/hadoop-root/dfs/namesecondary
'
hive.optimize.acid.meta.columnstrue
/
&dfs.provided.aliasmap.inmemory.enabledfalse
Q
%net.topology.node.switch.mapping.impl(org.apache.hadoop.net.ScriptBasedMapping
&
!mapreduce.shuffle.max.connections0
0
)hive.optimize.bi.rewrite.cume_dist.sketchkll
 
hive.counters.group.nameHIVE
%
yarn.bin.path/opt/hadoop/bin/yarn
?
8yarn.client.application-client-protocol.poll-interval-ms200
2
+dfs.namenode.list.cache.pools.num.responses100
A
;hive.llap.daemon.metrics.timed.window.average.window.length1m

nfs.server.port2049
 
hive.groupby.skewindatafalse

hive.entity.separator@

dfs.checksum.typeCRC32C

fs.s3a.readahead.range64K
#
hive.mm.avoid.s3.globstatustrue
C
8dfs.client.read.short.circuit.replica.stale.threshold.ms1800000
'
ha.zookeeper.parent-znode
/hadoop-ha
(
 hive.exec.max.dynamic.partitions1000
2
)hive.repl.externaltable.snapshotdiff.copyfalse
(
#yarn.sharedcache.admin.thread-count1
-
 mapreduce.jobhistory.http.policy	HTTP_ONLY

fs.s3a.attempts.maximum20
*
$dfs.datanode.lazywriter.interval.sec60

hive.metastore.use.SSLfalse
8
2yarn.log-aggregation.retain-check-interval-seconds-1
^
*fs.viewfs.overload.scheme.target.wasb.impl0org.apache.hadoop.fs.azure.NativeAzureFileSystem
B
$hive.repl.replica.functions.root.dir/user/root/repl/functions/
B
;mapreduce.jobhistory.intermediate-user-done-dir.permissions770
%
hive.metastore.execute.setugitrue
0
'hive.mapjoin.testing.no.hash.table.loadfalse
0
$mapreduce.job.split.metainfo.maxsize10000000
:
-mapreduce.input.fileinputformat.split.maxsize	256000000
%
hive.mapjoin.bucket.cache.size100
7
'hadoop.security.random.device.file.path/dev/urandom
!
hive.druid.metadata.basedruid
$
hive.llap.io.allocator.mmapfalse
8
&hive.druid.coordinator.address.defaultlocalhost:8081
5
-hive.avro.timestamp.legacy.conversion.enabledtrue
¨
hive.conf.hidden.listŽjavax.jdo.option.ConnectionPassword,hive.server2.keystore.password,hive.server2.webui.keystore.password,hive.druid.metadata.password,fs.s3.awsAccessKeyId,fs.s3.awsSecretAccessKey,fs.s3n.awsAccessKeyId,fs.s3n.awsSecretAccessKey,fs.s3a.access.key,fs.s3a.secret.key,fs.s3a.proxy.password,dfs.adls.oauth2.credential,fs.adl.oauth2.credential,fs.azure.account.oauth2.client.secret,hive.zookeeper.ssl.keystore.location,hive.zookeeper.ssl.keystore.password,hive.zookeeper.ssl.truststore.location,hive.zookeeper.ssl.truststore.password
4
+hive.query.results.cache.max.entry.lifetime3600s
3
,dfs.federation.router.dn-report.cache-expire10s

dfs.replication.max512

hive.fetch.task.cachingtrue

dfs.image.parallel.threads4
+
&fs.s3a.select.input.csv.comment.marker#
G
hive.script.serde2org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
3
.yarn.resourcemanager.admin.client.thread-count1
,
'hive.server2.limit.connections.per.user0
5
fs.ftp.impl&org.apache.hadoop.fs.ftp.FTPFileSystem
7
/hive.optimize.shared.work.parallel.edge.supporttrue
;
6mapreduce.input.fileinputformat.split.minsize.per.node1
$
hive.optimize.bucketmapjoinfalse
1
)hive.vectorized.use.row.serde.deserializetrue
9
0hive.vectorized.execution.mapjoin.minmax.enabledfalse
3
.yarn.resourcemanager.zk-appid-node.split-index0
1
*dfs.domain.socket.disable.interval.seconds600
3
.hive.optimize.sort.dynamic.partition.threshold0
<
5hadoop.security.kms.client.failover.sleep.base.millis100
‘
:hive.auto.convert.sortmerge.join.bigtable.selection.policySorg.apache.hadoop.hive.ql.optimizer.AvgPartitionSizeBasedBigTableSelectorForAutoSMJ
2
#yarn.node-labels.configuration-typecentralized
)
yarn.timeline-service.ttl-ms	604800000
)
!hive.timedout.txn.reaper.interval180s
6
-mapreduce.task.exit.timeout.check-interval-ms20000
$
hadoop.http.idle_timeout.ms60000
4
,hive.server2.thrift.http.compression.enabledtrue
!
mapreduce.map.speculativetrue
/
&yarn.timeline-service.recovery.enabledfalse
d
#hive.security.authenticator.manager=org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator
&
tez.submit.host.address172.19.0.10
'
!dfs.namenode.name.cache.threshold10
G
Ayarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms20
7
.dfs.namenode.max.extra.edits.segments.retained10000
“
3yarn.nodemanager.elastic-memory-control.oom-handler\org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.DefaultOOMHandler

hive.llap.io.lrfu.lambda0.1
,
hive.io.rcfile.record.interval
2147483647

hive.split.updatetrue
#
hive.strict.managed.tablesfalse

hive.optimize.limittrue

dfs.client.mmap.enabledtrue
$
hive.druid.metadata.db.typemysql

hadoop.zk.timeout-ms10000
-
%hive.optimize.bi.rewrite.rank.enabledtrue
-
%hive.vectorized.execution.ptf.enabledtrue
*
"hive.optimize.shared.work.extendedtrue
&
hive.test.authz.sstd.hs2.modefalse
.
'dfs.client.hedged.read.threshold.millis500
=
5yarn.resourcemanager.fs.state-store.retry-interval-ms1000
.
&hive.vectorized.row.identifier.enabledtrue
8
0hive.server2.thrift.resultset.default.fetch.size1000
0
*hive.vectorized.testing.reducer.batch.size-1
<
fs.AbstractFileSystem.har.implorg.apache.hadoop.fs.HarFs
=
4hive.query.reexecution.always.collect.operator.statsfalse

hive.repl.cm.retain10d
2
)dfs.datanode.ec.reconstruction.validationfalse
$
hive.merge.cardinality.checktrue
+
&hive.server2.thrift.min.worker.threads5
,
%hive.optimize.bi.rewrite.ntile.sketchkll
+
!dfs.qjournal.new-epoch.timeout.ms120000
>
.hive.server2.authentication.ldap.groupClassKeygroupOfNames
0
+hive.server2.tez.sessions.per.default.queue1
7
.yarn.timeline-service.webapp.rest-csrf.enabledfalse
&
hive.server2.thrift.http.port10001
G
+hive.server2.logging.operation.log.location/tmp/root/operation_logs
S
javax.jdo.option.ConnectionURL1jdbc:derby:;databaseName=metastore_db;create=true
s
"yarn.timeline-service.reader.classMorg.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineReaderImpl
@
7yarn.app.mapreduce.am.staging-dir.erasurecoding.enabledfalse
8
*dfs.datanode.network.counts.cache.max.size
2147483647
s
"yarn.timeline-service.writer.classMorg.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineWriterImpl
9
2hive.server2.historic.operation.log.check.interval15m
6
.dfs.federation.router.mount-table.cache.enabletrue
3
)dfs.qjournal.get-journal-state.timeout.ms120000
*
!dfs.qjournal.http.read.timeout.ms60000
'
hive.multigroupby.singlereducertrue
x
9yarn.timeline-service.entity-group-fs-store.summary-store;org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore
/
*hive.compactor.history.retention.succeeded3

tez.queue.namedefault
-
'dfs.namenode.snapshot.skiplist.interval10
!
fs.s3a.socket.recv.buffer8192
#
hive.txn.nonacid.read.lockstrue
^
0mapreduce.output.fileoutputformat.compress.codec*org.apache.hadoop.io.compress.DefaultCodec
7
2dfs.datanode.fsdatasetcache.max.threads.per.volume4
9
1hive.optimize.cte.materialize.full.aggregate.onlytrue
9
3yarn.sharedcache.store.in-memory.initial-delay-mins10
4
#mapreduce.jobhistory.webapp.address0.0.0.0:19888
5
fs.adl.impl&org.apache.hadoop.fs.adl.AdlFileSystem
$
mapreduce.task.userlog.limit.kb0
4
.mapreduce.job.local-fs.single-disk-limit.bytes-1

hive.txn.timeout300s
$
hive.llap.io.use.fileid.pathtrue

.yarn.router.rmadmin.interceptor-class.pipelineMorg.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor
/
yarn.sharedcache.webapp.address0.0.0.0:8788
%
hadoop.fuse.connection.timeout300
5
!dfs.http.client.retry.policy.spec10000,6,60000,10
$
hive.limit.optimize.limit.file10
3
*hive.exec.script.allow.partial.consumptionfalse
I
?yarn.resourcemanager.rm.container-allocation.expiry-interval-ms600000

ipc.server.max.connections0
4
hive.zookeeper.namespacehive_zookeeper_namespace
+
!hive.server2.long.polling.timeout5000ms
)
!yarn.app.mapreduce.am.resource.mb1536
0
&mapreduce.shuffle.transfer.buffer.size131072
0
)hive.server2.thrift.worker.keepalive.time60s
,
$hive.server2.allow.user.substitutiontrue
%
dfs.namenode.audit.log.asyncfalse
&
dfs.datanode.disk.check.timeout10m

fs.s3a.committer.threads8
*
"hive.tez.dynamic.partition.pruningtrue
=
8yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts3
/
(hive.exec.max.dynamic.partitions.pernode100

hive.llap.exec.use.fqdntrue

hive.local.time.zoneLOCAL
.
'hive.server2.tez.wm.am.registry.timeout30s
K
Cyarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs3600
.
'hive.llap.io.lrfu.hotbuffers.percentage0.1
-
(yarn.scheduler.maximum-allocation-vcores4
'
!tez.am.task.listener.thread-count30
!
mapreduce.job.acl-modify-job 
E
fs.AbstractFileSystem.abfs.impl"org.apache.hadoop.fs.azurebfs.Abfs
G
=yarn.resourcemanager.activities-manager.app-activities.ttl-ms600000
!
fs.azure.sas.expiry.period90d

fs.s3a.secret.key 
!
dfs.qjm.operations.timeout60s
1
,dfs.namenode.stale.datanode.minimum.interval3

hive.lock.numretries100
G
1hive.server2.active.passive.ha.registry.namespacehs2ActivePassiveHA
;
1dfs.federation.router.store.membership.expiration300000
;
6hadoop.security.groups.cache.background.reload.threads3

hive.auto.convert.jointrue
7
.hive.server2.support.dynamic.service.discoveryfalse
C
<yarn.resourcemanager.delegation-token-renewer.thread-timeout60s
<
7mapreduce.input.fileinputformat.list-status.num-threads1
5
,dfs.federation.router.client.reject.overloadfalse
I
;yarn.nodemanager.container-log-monitor.dir-size-limit-bytes
1000000000
C
6hadoop.security.group.mapping.ldap.posix.attr.gid.name	gidNumber
!
dfs.datanode.du.reserved.pct0
-
#hive.llap.io.encode.slice.row.count100000
.
!dfs.namenode.resource.du.reserved	104857600
#
hive.create.as.insert.onlyfalse
2
)dfs.federation.router.connection.clean.ms10000
w
#dfs.federation.router.metrics.classPorg.apache.hadoop.hdfs.server.federation.metrics.FederationRPCPerformanceMonitor
*
#mapreduce.shuffle.listen.queue.size128
!
datanucleus.cache.level2false

hive.llap.am.use.fqdntrue
:
2yarn.nodemanager.recovery.compaction-interval-secs3600
1
(dfs.namenode.edits.noeditlogchannelflushfalse

yarn.http.policy	HTTP_ONLY

mapreduce.map.maxattempts4
2
*hadoop.security.groups.cache.warn.after.ms5000
6
.datanucleus.rdbms.useLegacyNativeValueStrategytrue
G
>dfs.client.write.byte-array-manager.count-reset-time-period-ms10000
@
/yarn.nodemanager.webapp.rest-csrf.custom-headerX-XSRF-Header
c
$yarn.node-labels.fs-store.impl.class;org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore
,
#hive.repl.bootstrap.external.tablesfalse
6
-mapreduce.jobhistory.webapp.rest-csrf.enabledfalse

dfs.http.policy	HTTP_ONLY
,
dfs.balancer.max-size-to-move10737418240
6
-dfs.datanode.sync.behind.writes.in.backgroundfalse
:
3dfs.namenode.reencrypt.throttle.limit.updater.ratio1.0

hive.mv.files.thread15
)
 hive.llap.skip.compile.udf.checkfalse
4
$dfs.namenode.secondary.https-address0.0.0.0:9869
4
-hive.llap.mapjoin.memory.oversubscribe.factor0.2

dfs.mover.address	0.0.0.0:0

hive.arrow.batch.size1000
H
@mapreduce.job.local-fs.single-disk-limit.check.kill-limit-exceedtrue

hive.reorder.nway.joinstrue
'
hive.merge.orcfile.stripe.leveltrue
0
)hive.server2.operation.log.fetch.maxBytes4Mb
"
hive.exec.compress.outputfalse
,
fs.viewfs.rename.strategySAME_MOUNTPOINT
 
hadoop.proxyuser.hive.hosts*
F
;yarn.resourcemanager.node-labels.provider.fetch-interval-ms1800000
1
)yarn.nodemanager.container-metrics.enabletrue
0
'hive.explain.dependency.append.tasktypefalse
\
(mapreduce.job.map.output.collector.class0org.apache.hadoop.mapred.MapTask$MapOutputBuffer
!
fs.s3a.fast.upload.bufferdisk
&
hive.optimize.bucketingsortingtrue
*
"hive.optimize.shared.work.dppuniontrue
,
&dfs.datanode.replica.cache.expiry.time5m
"
hive.scratch.dir.permission700
*
%dfs.edit.log.transfer.bandwidthPerSec0
:
4hive.notification.sequence.lock.retry.sleep.interval10

hive.repl.cm.interval3600s
&
dfs.ha.tail-edits.in-progressfalse
0
(dfs.federation.router.heartbeat.interval5000
(
tez.am.tez-ui.webservice.enablefalse
.
%hive.parquet.date.proleptic.gregorianfalse
*
#dfs.client.datanode-restart.timeout30s
:
5hadoop.security.kms.client.authentication.retry-count1
D
6yarn.nodemanager.runtime.linux.runc.image-toplevel-dir
/runc-root
9
2hive.server2.sleep.interval.between.start.attempts60s
!
fs.s3a.awsAccessKeyIddatalake
„
*yarn.nodemanager.containers-launcher.classVorg.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher
@
7hive.security.authorization.scheduled.queries.supportedfalse
(
hive.repl.approx.max.load.tasks10000
K
7yarn.resourcemanager.webapp.rest-csrf.methods-to-ignoreGET,OPTIONS,HEAD

mapreduce.job.max.map-1
,
$hive.metastore.client.socket.timeout600s
*
"javax.jdo.option.DetachAllOnCommittrue

ftp.blocksize67108864
(
"hive.llap.daemon.yarn.container.mb-1
-
#tez.runtime.shuffle.connect.timeout180000
t
'dfs.namenode.decommission.monitor.classIorg.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor
M
%javax.jdo.option.ConnectionDriverName$org.apache.derby.jdbc.EmbeddedDriver
)
$dfs.namenode.replication.max-streams2
$
hive.druid.http.read.timeoutPT1M
 
nfs.allow.insecure.portstrue
/
)yarn.sharedcache.nm.uploader.thread-count20
(
 hive.query.results.cache.enabledtrue
:
1hive.metastore.orm.retrieveMapNullsAsEmptyStringsfalse
8
/yarn.nodemanager.elastic-memory-control.enabledfalse
0
#yarn.log-aggregation.debug.filesize	104857600
,
$hive.blobstore.optimizations.enabledtrue
4
,yarn.app.mapreduce.client.job.retry-interval2000

hive.llap.orc.gap.cachetrue

hive.merge.tezfilesfalse
3
+yarn.scheduler.configuration.store.max-logs1000
*
!hive.legacy.schema.for.all.serdesfalse
)
!hive.repl.include.external.tablestrue
+
#hive.llap.nodehealthchecks.mintasks2000
„$
0hive.security.authorization.sqlstd.confwhitelistÏ#hive\.auto\..*|hive\.cbo\..*|hive\.convert\..*|hive\.druid\..*|hive\.exec\.dynamic\.partition.*|hive\.exec\.max\.dynamic\.partitions.*|hive\.exec\.compress\..*|hive\.exec\.infer\..*|hive\.exec\.mode.local\..*|hive\.exec\.orc\..*|hive\.exec\.parallel.*|hive\.explain\..*|hive\.fetch.task\..*|hive\.groupby\..*|hive\.hbase\..*|hive\.index\..*|hive\.index\..*|hive\.intermediate\..*|hive\.jdbc\..*|hive\.join\..*|hive\.limit\..*|hive\.log\..*|hive\.mapjoin\..*|hive\.merge\..*|hive\.optimize\..*|hive\.materializedview\..*|hive\.orc\..*|hive\.outerjoin\..*|hive\.parquet\..*|hive\.ppd\..*|hive\.prewarm\..*|hive\.query\.name|hive\.server2\.thrift\.resultset\.default\.fetch\.size|hive\.server2\.proxy\.user|hive\.skewjoin\..*|hive\.smbjoin\..*|hive\.stats\..*|hive\.strict\..*|hive\.tez\..*|hive\.vectorized\..*|hive\.query\.reexecution\..*|hive\.query\.exclusive\.lock|reexec\.overlay\..*|fs\.defaultFS|ssl\.client\.truststore\.location|distcp\.atomic|distcp\.ignore\.failures|distcp\.preserve\.status|distcp\.preserve\.rawxattrs|distcp\.sync\.folders|distcp\.delete\.missing\.source|distcp\.keystore\.resource|distcp\.liststatus\.threads|distcp\.max\.maps|distcp\.copy\.strategy|distcp\.skip\.crc|distcp\.copy\.overwrite|distcp\.copy\.append|distcp\.map\.bandwidth\.mb|distcp\.dynamic\..*|distcp\.meta\.folder|distcp\.copy\.listing\.class|distcp\.filters\.class|distcp\.options\.skipcrccheck|distcp\.options\.m|distcp\.options\.numListstatusThreads|distcp\.options\.mapredSslConf|distcp\.options\.bandwidth|distcp\.options\.overwrite|distcp\.options\.strategy|distcp\.options\.i|distcp\.options\.p.*|distcp\.options\.update|distcp\.options\.delete|mapred\.map\..*|mapred\.reduce\..*|mapred\.output\.compression\.codec|mapred\.job\.queue\.name|mapred\.output\.compression\.type|mapred\.min\.split\.size|mapreduce\.job\.reduce\.slowstart\.completedmaps|mapreduce\.job\.queuename|mapreduce\.job\.tags|mapreduce\.input\.fileinputformat\.split\.minsize|mapreduce\.map\..*|mapreduce\.reduce\..*|mapreduce\.output\.fileoutputformat\.compress\.codec|mapreduce\.output\.fileoutputformat\.compress\.type|oozie\..*|tez\.am\..*|tez\.task\..*|tez\.runtime\..*|tez\.queue\.name|hive\.transpose\.aggr\.join|hive\.exec\.reducers\.bytes\.per\.reducer|hive\.client\.stats\.counters|hive\.create\.as\.acid|hive\.create\.as\.external\.legacy|hive\.exec\.default\.partition\.name|hive\.exec\.drop\.ignorenonexistent|hive\.counters\.group\.name|hive\.default\.fileformat\.managed|hive\.enforce\.bucketmapjoin|hive\.enforce\.sortmergebucketmapjoin|hive\.cache\.expr\.evaluation|hive\.query\.result\.fileformat|hive\.hashtable\.loadfactor|hive\.hashtable\.initialCapacity|hive\.ignore\.mapjoin\.hint|hive\.limit\.row\.max\.size|hive\.mapred\.mode|hive\.map\.aggr|hive\.compute\.query\.using\.stats|hive\.exec\.rowoffset|hive\.variable\.substitute|hive\.variable\.substitute\.depth|hive\.autogen\.columnalias\.prefix\.includefuncname|hive\.autogen\.columnalias\.prefix\.label|hive\.exec\.check\.crossproducts|hive\.cli\.tez\.session\.async|hive\.compat|hive\.create\.as\.insert\.only|hive\.display\.partition\.cols\.separately|hive\.error\.on\.empty\.partition|hive\.execution\.engine|hive\.exec\.copyfile\.maxsize|hive\.exim\.uri\.scheme\.whitelist|hive\.file\.max\.footer|hive\.insert\.into\.multilevel\.dirs|hive\.localize\.resource\.num\.wait\.attempts|hive\.multi\.insert\.move\.tasks\.share\.dependencies|hive\.query\.results\.cache\.enabled|hive\.query\.results\.cache\.wait\.for\.pending\.results|hive\.support\.quoted\.identifiers|hive\.resultset\.use\.unique\.column\.names|hive\.analyze\.stmt\.collect\.partlevel\.stats|hive\.exec\.schema\.evolution|hive\.server2\.logging\.operation\.level|hive\.server2\.thrift\.resultset\.serialize\.in\.tasks|hive\.support\.special\.characters\.tablename|hive\.exec\.job\.debug\.capture\.stacktraces|hive\.exec\.job\.debug\.timeout|hive\.llap\.io\.enabled|hive\.llap\.io\.use\.fileid\.path|hive\.llap\.daemon\.service\.hosts|hive\.llap\.execution\.mode|hive\.llap\.auto\.allow\.uber|hive\.llap\.auto\.enforce\.tree|hive\.llap\.auto\.enforce\.vectorized|hive\.llap\.auto\.enforce\.stats|hive\.llap\.auto\.max\.input\.size|hive\.llap\.auto\.max\.output\.size|hive\.llap\.skip\.compile\.udf\.check|hive\.llap\.client\.consistent\.splits|hive\.llap\.enable\.grace\.join\.in\.llap|hive\.llap\.allow\.permanent\.fns|hive\.exec\.max\.created\.files|hive\.exec\.reducers\.max|hive\.reorder\.nway\.joins|hive\.output\.file\.extension|hive\.exec\.show\.job\.failure\.debug\.info|hive\.exec\.tasklog\.debug\.timeout|hive\.query\.id|hive\.query\.tag
+
"hive.tez.dag.status.check.interval500ms
!
fs.har.impl.disable.cachetrue
*
!hive.external.table.purge.defaultfalse
 
hive.stats.map.num.entries10

hive.in.ide.testfalse
H
hive.llap.io.encode.formats)org.apache.hadoop.mapred.TextInputFormat,
"
hive.exec.mode.local.autofalse
'
"dfs.namenode.upgrade.domain.factor1
5
,mapreduce.jobhistory.minicluster.fixed.portsfalse
0
(hive.metastore.aggregate.stats.cache.fpp0.01
2
+dfs.namenode.redundancy.considerLoad.factor2.0
q
 yarn.resourcemanager.store.classMorg.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore

hive.unlock.numretries10
1
!dfs.federation.router.rpc-address0.0.0.0:8888
1
)fs.s3a.committer.staging.unique-filenamestrue
#
hive.llap.daemon.num.executors4
9
1hive.llap.daemon.task.scheduler.enable.preemptiontrue
)
!dfs.namenode.support.allow.formattrue

hive.optimize.groupbytrue
E
=yarn.nodemanager.container-executor.exit-code-file.timeout-ms2000
!
hive.druid.bitmap.typeroaring
6
.hive.server2.tez.sessions.custom.queue.allowedtrue
!
dfs.content-summary.limit5000
2
%hive.exec.orc.blob.storage.split.size	134217728
o
)yarn.nodemanager.container-executor.classBorg.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor
/
'yarn.app.mapreduce.shuffle.log.separatetrue
7
.dfs.federation.router.mount-table.cache.updatefalse
6
*hadoop.user.group.static.mapping.overridesdr.who=;
(
 tez.runtime.optimize.local.fetchtrue
3
"dfs.federation.router.http-address0.0.0.0:50071
2
"yarn.nodemanager.amrmproxy.address0.0.0.0:8049
&
hive.server.read.socket.timeout10s
8
0hive.exec.orc.writer.llap.memory.manager.enabledtrue
1
$dfs.client.key.provider.cache.expiry	864000000
0
(tez.runtime.shuffle.fetch.buffer.percent0.70
k
dfs.block.replicator.classnameIorg.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault
4
/yarn.nodemanager.collector-service.thread-count5
¯
2yarn.nodemanager.runtime.linux.docker.capabilitiesyCHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE
0
#hive.server2.thrift.client.password	anonymous
&
hive.repl.filter.transactionsfalse
3
*ipc.client.fallback-to-simple-auth-allowedfalse
)
mapred.bin.path/opt/hadoop/bin/mapred
0
#yarn.nodemanager.remote-app-log-dir	/tmp/logs
<
3dfs.storage.policy.satisfier.recheck.timeout.millis60000
9
1hive.repl.externaltable.snapshot.overwrite.targettrue
9
1dfs.federation.router.connection.min-active-ratio0.5f
\
Uyarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-size500
G
Ayarn.timeline-service.entity-group-fs-store.scan-interval-seconds60

dfs.xframe.enabledtrue
'
hive.default.fileformat.managednone

dfs_webhdfs_enabledtrue
"
hive.extend.bucketid.rangetrue
)
dfs.datanode.http.address0.0.0.0:9864
(
fs.s3a.s3guard.cli.prune.age86400000
<
7hive.llap.task.scheduler.num.schedulable.tasks.per.node0
.
&hive.optimize.bi.rewrite.ntile.enabledtrue

hive.llap.io.memory.size1Gb
'
hadoop.jetty.logs.serve.aliasestrue
&
hive.strict.checks.type.safetytrue
-
#dfs.webhdfs.ugi.expire.after.access600000
.
%hive.server2.async.exec.async.compilefalse
#
mapreduce.jobhistory.admin.acl*
,
hive.llap.auto.max.input.size10737418240
?
6yarn.resourcemanager.node-removal-untracked.timeout-ms60000
'
 hive.limit.pushdown.memory.usage0.1
?
9hive.llap.memory.oversubscription.max.executors.per.query-1
*
 tez.runtime.shuffle.read.timeout180000
-
$mapreduce.jobhistory.recovery.enablefalse
3
#yarn.resourcemanager.webapp.address0.0.0.0:8088
9
2yarn.sharedcache.store.in-memory.check-period-mins720
9
1hive.metastore.batch.retrieve.table.partition.max1000
.
 hive.blobstore.supported.schemes
s3,s3a,s3n
2
-dfs.client.test.drop.namenode.response.number0
%
hive.compute.splits.num.threads10
 
fs.s3a.aws.credentials.providerü
    org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider,
    org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider,
    com.amazonaws.auth.EnvironmentVariableCredentialsProvider,
    org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider
  
=
0hive.tez.dynamic.partition.pruning.max.data.size	104857600
¢
:yarn.nodemanager.resource-plugins.fpga.vendor-plugin.classdorg.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin
2
*dfs.namenode.ec.userdefined.policy.allowedtrue
.
&hive.orc.splits.allow.synthetic.fileidtrue
&
yarn.timeline-service.enabledfalse
*
hive.zookeeper.session.timeout120000ms
(
hive.concatenate.external.tablefalse
M
hive.fetch.output.serde2org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
W
(hadoop.http.cross-origin.allowed-headers+X-Requested-With,Content-Type,Accept,Origin

mapreduce.task.profilefalse
*
yarn.router.webapp.address0.0.0.0:8089
+
hive.skewjoin.mapjoin.min.split33554432
$
yarn.nodemanager.hostname0.0.0.0
$
mapreduce.task.exit.timeout60000
@
:yarn.resourcemanager.nm-container-queuing.max-queue-length15
*
#hive.server2.session.check.interval15m
@
7hive.vectorized.execution.filesink.arrow.native.enabledfalse
-
%fs.azure.authorization.caching.enabletrue
*
 dfs.client.mmap.retry.timeout.ms300000
.
&fs.s3a.committer.abort.pending.uploadstrue
G
@yarn.resourcemanager.nm-container-queuing.max-queue-wait-time-ms100
 
dfs.permissions.enabledfalse
$
hive.ppd.recognizetransivitytrue
<
fs.AbstractFileSystem.hdfs.implorg.apache.hadoop.fs.Hdfs
6
.yarn.nodemanager.container-localizer.log.levelINFO
Q
hadoop.http.filter.initializers.org.apache.hadoop.http.lib.StaticUserWebFilter
-
$yarn.webapp.filter-invalid-xml-charsfalse
T
@yarn.nodemanager.runtime.linux.docker.allowed-container-networkshost,none,bridge
1
'dfs.qjournal.accept-recovery.timeout.ms120000
+
"hive.optimize.shared.work.semijoinfalse
¯
@yarn.nodemanager.runtime.linux.runc.manifest-to-resources-pluginkorg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.HdfsManifestToResourcesPlugin
&
fs.s3a.committer.magic.enabledtrue
=
-yarn.resourcemanager.resource-tracker.address0.0.0.0:8031

hive.llap.io.trace.size2Mb
$
rpc.metrics.quantile.enablefalse
B
9dfs.client.deadnode.detection.probe.connection.timeout.ms20000
+
#hive.query.planmapper.link.relnodestrue
0
'dfs.ha.nn.not-become-active-in-safemodefalse
4
"hive.kudu.master.addresses.defaultlocalhost:7050
*
%dfs.datanode.failed.volumes.tolerated0
>
6yarn.nodemanager.disk-health-checker.min-healthy-disks0.25
.
(hive.server2.tez.session.lifetime.jitter3h
)
#hive.orc.compute.splits.num.threads10
"
hive.llap.daemon.web.port15002
K
hive.script.recordwriter/org.apache.hadoop.hive.ql.exec.TextRecordWriter
.
(hadoop.caller.context.signature.max.size40
#
fs.s3a.connection.timeout200000
-
$hive.strict.checks.cartesian.productfalse
E
hive.txn.manager1org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager
 
hive.variable.substitutetrue
+
&fs.s3a.s3guard.ddb.table.capacity.read0
<
3yarn.nodemanager.pluggable-device-framework.enabledfalse
(
#hive.llap.daemon.vcpus.per.instance4
&
fs.s3a.change.detection.sourceetag
(
!hive.metastore.server.min.threads200
J
Ayarn.resourcemanager.delayed.delegation-token.removal-interval-ms30000
&
!hive.llap.plugin.rpc.num.handlers1
&
 dfs.client.failover.max.attempts15
,
!hive.tez.min.bloom.filter.entries1000000
5
,yarn.nodemanager.webapp.cross-origin.enabledfalse
2
)mapreduce.job.encrypted-intermediate-datafalse
K
Byarn.nodemanager.opportunistic-containers-use-pause-for-preemptionfalse
>
4dfs.client.read.shortcircuit.streams.cache.expiry.ms300000
0
(hive.optimize.partition.columns.separatetrue

hive.test.load.interval10ms
#
dfs.webhdfs.oauth2.enabledfalse
C
:yarn.resourcemanager.resource-tracker.nm.ip-hostname-checkfalse
0
'hive.server2.wm.allow.any.pool.via.jdbcfalse
-
'hive.async.cleanup.service.thread.count10
"
hive.metastore.dml.eventsfalse
'
hadoop.ssl.require.client.certfalse

hive.log.every.n.records0
F
mapreduce.jobhistory.keytab'/etc/security/keytab/jhs.service.keytab
/
&hive.orc.cache.stripe.details.mem.size256Mb
.
'hive.llap.task.scheduler.locality.delay0ms
)
hive.repl.cmrootdir/user/root/cmroot/
1
(yarn.intermediate-data-encryption.enablefalse
;
4hive.llap.task.scheduler.node.disable.backoff.factor1.5
6
/hive.map.aggr.hash.force.flush.memory.threshold0.9
0
'hive.repl.dump.skip.immutable.data.copyfalse

dfs.client.contextdefault
.
%yarn.system-metrics-publisher.enabledfalse
@
:yarn.timeline-service.entity-group-fs-store.app-cache-size10
8
,dfs.namenode.delegation.token.renew-interval86400000
Ž
hadoop.tags.systemxYARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT
      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL
>
fs.AbstractFileSystem.s3a.implorg.apache.hadoop.fs.s3a.S3A

ipc.client.tcpnodelaytrue
+
#hive.repl.ranger.target.deny.policytrue
5
-hive.vectorized.groupby.complex.types.enabledtrue
,
#hive.avro.timestamp.skip.conversionfalse
;
,yarn.resourcemanager.metrics.runtime.buckets60,300,1440
*
"hive.metastore.schema.verificationtrue
(
dfs.blockreport.intervalMsec21600000
C
9hive.llap.am.liveness.connection.sleep.between.retries.ms2000ms
8
/hive.llap.io.proactive.eviction.instant.deallocfalse
`
tez.am.dag.scheduler.classBorg.apache.tez.dag.app.dag.impl.DAGSchedulerNaturalOrderControlled

io.map.index.skip0
5
hive.druid.working.directory/tmp/workingDirectory
*
hive.cbo.fallback.strategyCONSERVATIVE
A
8hive.query.results.cache.nontransactional.tables.enabledfalse
/
'hive.llap.daemon.memory.per.instance.mb4096
0
(hive.log.explain.output.include.extendedtrue
<
7dfs.namenode.missing.checkpoint.periods.before.shutdown3
-
%hive.stats.correlated.multi.key.joinstrue
%
tfile.fs.output.buffer.size262144
+
&dfs.client.failover.connection.retries0
&
dfs.edit.log.transfer.timeout30000
)
#dfs.namenode.top.window.num.buckets10
0
)hive.compactor.active.delta.dir.threshold200
8
(yarn.sharedcache.uploader.server.address0.0.0.0:8046

hive.metastore.db.typeDERBY

hive.tez.cpu.vcores-1
'
 hive.txn.acid.dir.cache.duration120
4
,hive.compactor.acid.metrics.logger.frequency360m
.
&hive.parquet.timestamp.skip.conversiontrue
3
+hive.tez.task.scale.memory.reserve.fraction-1.0
+
hadoop.registry.zk.quorumlocalhost:2181
-
(hadoop.http.cross-origin.allowed-origins*

dfs.datanode.du.reserved0
C
hadoop.registry.system.acls$sasl:yarn@, sasl:mapred@, sasl:hdfs@
,
&datanucleus.connectionPool.maxPoolSize10

hive.merge.nway.joinsfalse
q
$mapreduce.task.profile.reduce.paramsI-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
6
-hive.streaming.auto.flush.check.interval.size100Mb
4
,hive.materializedview.rewriting.sql.subquerytrue
E
-hadoop.http.authentication.kerberos.principalHTTP/_HOST@LOCALHOST
'
hive.optimize.sampling.orderbyfalse
D
>dfs.federation.router.mount-table.cache.update.client.max.time5m
D
?yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb0
'
!hive.llap.io.lrfu.bp.wrapper.size64
'
dfs.datanode.transferTo.allowedtrue
5
/hive.server2.iceberg.metadata.generator.threads10

hive.exec.script.trustfalse
<
4hive.mapjoin.followby.gby.localtask.max.memory.usage0.55
-
%hive.exec.show.job.failure.debug.infotrue
&
dfs.namenode.name.dir.restorefalse
(
!hive.cbo.costmodel.local.fs.write4.0
8
.dfs.namenode.full.block.report.lease.length.ms300000
6
.hive.llap.io.encode.vector.serde.async.enabledtrue
.
&hive.map.aggr.hash.min.reduction.statstrue
a
tez.application.tagsIroot_20241101180712_0964671c-f723-4c65-b7ad-9bdb211e3a9b,userid=anonymous
&
hive.server2.in.place.progresstrue
(
!hive.zookeeper.connection.timeout15s
 
hadoop.http.logs.enabledtrue

hive.stats.ndv.error20.0
;
2hadoop.security.group.mapping.ldap.read.timeout.ms60000
N
Gyarn.resourcemanager.activities-manager.app-activities.max-queue-length100
1
(dfs.namenode.delegation.token.always-usefalse
/
 hive.server2.zookeeper.namespacehiveserver2
D
>yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory10
-
$hive.druid.indexer.memory.rownum.max75000
i
!hive.query.reexecution.strategiesDoverlay,reoptimize,reexecute_lost_am,dagsubmit,recompile_without_cbo
J
Ayarn.nodemanager.runtime.linux.runc.privileged-containers.allowedfalse
-
&hive.metastore.client.cache.v2.maxSize1Gb
-
'dfs.client.read.striped.threadpool.size18
8
3hive.llap.daemon.metrics.simple.average.data.points0
)
 hive.server2.xsrf.filter.enabledfalse
(
 hive.llap.io.allocator.alloc.max16Mb
,
'mapreduce.job.cache.limit.max-resources0
*
!yarn.log-aggregation.file-formatsTFile
1
$hive.exec.reducers.bytes.per.reducer	256000000

hive.in.ssl.testfalse
.
&hive.metastore.client.capability.checktrue
/
)fs.s3a.select.output.csv.record.delimiter\n
%
datanucleus.storeManagerTyperdbms
,
$dfs.namenode.resource.check.interval5000
.
(mapreduce.jobhistory.client.thread-count10
.
)dfs.namenode.snapshot.skiplist.max.levels0
3
,tez.am.proportion.running.tasks.speculatable0.1
>
 hive.exec.default.partition.name__HIVE_DEFAULT_PARTITION__
;
6mapreduce.input.fileinputformat.split.minsize.per.rack1
*
$hive.metastore.event.expiry.duration0s
)
 mapreduce.job.emit-timeline-datafalse
,
'fs.s3a.select.input.csv.quote.character"
J
Byarn.nodemanager.runtime.linux.sandbox-mode.local-dirs.permissionsread
.
)hive.exec.mode.local.auto.input.files.max4
+
dfs.journalnode.rpc-address0.0.0.0:8485
U
-yarn.resourcemanager.leveldb-state-store.path$/tmp/hadoop-root/yarn/system/rmstore
6
/hive.tez.task.scale.memory.reserve-fraction.min0.3
3
+hive.orc.splits.ms.footer.cache.ppd.enabledtrue
*
!ipc.client.connection.maxidletime10000
+
"hive.optimize.skewjoin.compiletimefalse
 
hive.smbjoin.cache.rows10000
*
dfs.namenode.https-address0.0.0.0:9871
'
dfs.mover.max-no-move-interval60000
6
1hive.server2.limit.connections.per.user.ipaddress0
(
 hive.scheduled.queries.namespacehive
%
mapreduce.task.profile.reduces0-2
0
%dfs.namenode.ec.policies.max.cellsize4194304

hadoop.util.hash.typemurmur
%
hive.txn.ext.locking.enabledfalse
s
$hive.metastore.event.message.factoryKorg.apache.hadoop.hive.metastore.messaging.json.gzip.GzipJSONMessageEncoder
C
;yarn.resourcemanager.nodemanagers.heartbeat-interval-min-ms1000
!
dfs.namenode.replication.min1
!
hive.split.grouping.modequery
1
)hive.txn.acid.metrics.delta.pct.threshold0.01
E
fs.AbstractFileSystem.file.impl"org.apache.hadoop.fs.local.LocalFs
+
#dfs.namenode.gc.time.monitor.enabletrue
&
net.topology.script.number.args100
u
'dfs.datanode.httpserver.filter.handlersJorg.apache.hadoop.hdfs.server.datanode.web.RestCsrfPreventionFilterHandler
O
Fyarn.resourcemanager.container-tokens.master-key-rolling-interval-secs86400
@
7yarn.nodemanager.windows-container.memory-limit.enabledfalse
L
8yarn.timeline-service.webapp.rest-csrf.methods-to-ignoreGET,OPTIONS,HEAD
a
hadoop.security.group.mapping@org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback
;
2yarn.nodemanager.runtime.linux.docker.image-updatefalse
$
mapreduce.reduce.speculativetrue
T
hive.security.command.whitelist1set,reset,dfs,add,list,delete,reload,compile,llap
>
4yarn.nodemanager.localizer.cache.cleanup.interval-ms600000
-
$hive.repl.include.materialized.viewsfalse

fs.s3a.access.key 
1
'hadoop.security.auth_to_local.mechanismhadoop
8
/hive.optimize.topnkey.efficiency.check.nbatches10000
9
/yarn.nodemanager.node-labels.resync-interval-ms120000
P
Gyarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size10000
0
(fs.s3a.metadatastore.fail.on.write.errortrue
&
mapreduce.job.ubertask.enablefalse
9
/hive.llap.mapjoin.memory.monitor.check.interval100000
D
:yarn.timeline-service.entity-group-fs-store.retain-seconds604800
3
.hive.server2.thrift.client.connect.retry.limit1
)
 dfs.client.use.datanode.hostnamefalse
3
*yarn.app.mapreduce.am.webapp.https.enabledfalse
#
hive.llap.daemon.xmx.headroom5%
%
hive.llap.io.allocator.directtrue
'
"dfs.ha.tail-edits.namenode-retries3
]
)fs.viewfs.overload.scheme.target.ofs.impl0org.apache.hadoop.fs.ozone.RootedOzoneFileSystem
[
hive.default.rcfile.serde>org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe
!
hive.optimize.shared.worktrue
3
+mapreduce.job.finish-when-all-reducers-donetrue
,
#hadoop.registry.zk.retry.ceiling.ms60000
8
/hive.multi.insert.move.tasks.share.dependenciesfalse
$
hive.tez.max.partition.factor2.0
!
dfs.datanode.data.dir.perm700

hive.stats.estimatetrue
$
hive.optimize.clustered.sorttrue
;
2metastore.metastore.event.db.notification.api.authfalse
%
dfs.balancer.movedWinWidth5400000
¦
yarn.nodemanager.env-whitelistƒJAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ
#
dfs.namenode.xattrs.enabledtrue
2
-dfs.datanode.transfer.socket.send.buffer.size0
,
'fs.s3a.s3guard.ddb.table.capacity.write0
K
;yarn.nodemanager.linux-container-executor.cgroups.hierarchy/hadoop-yarn
0
+yarn.app.mapreduce.am.container.log.backups0
C
;yarn.resourcemanager.nodemanagers.heartbeat-interval-max-ms1000
A
9yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devicesauto
'
fs.s3a.select.input.compressionnone
:
0yarn.nodemanager.disk-health-checker.interval-ms120000
<
6dfs.federation.router.mount-table.cache.update.timeout1m
4
.hive.llap.io.proactive.eviction.sweep.interval5s
$
tez.am.launch.cmd-opts
 -Xmx1024m
0
)hive.repl.retry.max.delay.between.retries60m
7
0dfs.namenode.list.cache.directives.num.responses100
2
'hive.mapjoin.optimized.hashtable.wbsize8388608
)
!hive.server2.tez.session.lifetime162h
8
0hive.security.metastore.authorization.auth.readstrue
;
+yarn.timeline-service.reader.webapp.address0.0.0.0:8188
A
8dfs_namenode_datanode_registration_ip___hostname___checkfalse
?
9yarn.resourcemanager.resource-tracker.client.thread-count50

mapreduce.shuffle.port13562
9
0yarn.resourcemanager.webapp.cross-origin.enabledfalse
,
$hive.ppd.recognize.column.equalitiestrue
—
6yarn.scheduler.configuration.mutation.acl-policy.class]org.apache.hadoop.yarn.server.resourcemanager.scheduler.DefaultConfigurationMutationACLPolicy
:
1hive.exec.infer.bucket.sort.num.buckets.power.twofalse
A
1yarn.timeline-service.reader.webapp.https.address0.0.0.0:8190
;
2yarn.resourcemanager.proxy-user-privileges.enabledfalse
.
&dfs.federation.router.heartbeat.enabletrue

ftp.replication3
1
+yarn.sharedcache.cleaner.initial-delay-mins10
/
&hive.server2.thrift.http.max.idle.time1800s
:
1dfs.namenode.redundancy.considerLoadByStorageTypefalse
5
.hive.server2.thrift.http.worker.keepalive.time60s
&
hive.server2.webui.show.graphfalse

file.bytes-per-checksum512
0
)dfs.datanode.slow.io.warning.threshold.ms300
'
"mapreduce.task.skip.start.attempts2
L
Cyarn.resourcemanager.nodemanagers.heartbeat-interval-scaling-enablefalse
=
4mapreduce.job.dfs.storage.capacity.kill-limit-exceedfalse
!
hive.repl.failover.startfalse
;
2dfs.namenode.reject-unresolved-dn-topology-mappingfalse
U
Iyarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size10485760
/
(hive.server2.authentication.ldap.guidKeyuid
>
2yarn.resourcemanager.placement-constraints.handlerdisabled
.
yarn.sharedcache.admin.address0.0.0.0:8047
"
dfs.client.socket-timeout60000
L
 ipc.[port_number].callqueue.impl(java.util.concurrent.LinkedBlockingQueue
E
hive.tez.input.format,org.apache.hadoop.hive.ql.io.HiveInputFormat
6
-yarn.nodemanager.container-log-monitor.enablefalse
 
dfs.namenode.top.num.users10
@
7yarn.nodemanager.linux-container-executor.cgroups.mountfalse
-
%hive.llap.io.allocator.discard.methodboth
+
"hive.tez.cartesian-product.enabledfalse
o
'hive.llap.split.location.provider.classDorg.apache.hadoop.hive.ql.exec.tez.HostAffinitySplitLocationProvider
/
%fs.s3a.select.output.csv.quote.fieldsalways
"
mapreduce.job.classloaderfalse
$
yarn.log-aggregation-enablefalse
8
0mapreduce.reduce.shuffle.fetch.retry.interval-ms1000
8
0yarn.resourcemanager.nodemanager.minimum.versionNONE
#
hive.decode.partition.namefalse
:
3hadoop.security.kms.client.encrypted.key.cache.size500
M
Cyarn.resourcemanager.activities-manager.scheduler-activities.ttl-ms600000
V
4yarn.timeline-service.entity-group-fs-store.done-dir/tmp/entity-file-history/done/
<
3hive.server2.thrift.exponential.backoff.slot.length100ms
5
-mapreduce.job.end-notification.retry.interval1000
<
4yarn.nodemanager.local-cache.max-files-per-directory8192
X
+fs.viewfs.overload.scheme.target.https.impl)org.apache.hadoop.fs.http.HttpsFileSystem
8
0hive.vectorized.execution.mapjoin.native.enabledtrue
1
+hive.notification.sequence.lock.max.retries10
:
4dfs.client.deadnode.detection.probe.deadnode.threads10

hive.compat0.12
/
(hive.heap.memory.monitor.usage.threshold0.7
)
!dfs.namenode.lease-hard-limit-sec1200
,
hive.server2.thrift.client.user	anonymous
.
)hive.llap.io.encode.threadpool.multiplier2
'
hive.llap.io.encode.alloc.size256Kb
)
 hive.repl.include.atlas.metadatafalse
1
(dfs.namenode.audit.log.token.tracking.idfalse
,
dfs.permissions.superusergroup
supergroup
U
-hive.lockmgr.zookeeper.default.partition.name$__HIVE_DEFAULT_ZOOKEEPER_PARTITION__
‚
1hive.llap.daemon.wait.queue.comparator.class.nameMorg.apache.hadoop.hive.llap.daemon.impl.comparator.ShortestJobFirstComparator
#
hadoop.registry.zk.retry.times5

hive.merge.split.updatetrue
-
$hive.llap.daemon.output.service.port15003
'
"hive.compactor.cleaner.threads.num1
-
$hive.privilege.synchronizer.interval1800s
1
%dfs.balancer.getBlocks.min-block-size10485760
#
hive.llap.io.encode.enabledtrue

hive.test.mode.prefixtest_
,
$yarn.scheduler.maximum-allocation-mb8192
(
hive.exec.tasklog.debug.timeout20000

hive.mapred.local.mem0
'
hive.create.as.external.legacyfalse
0
 yarn.router.webapp.https.address0.0.0.0:8091
c
,mapreduce.outputcommitter.factory.scheme.s3a3org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory
?
7hive.metastore.client.drop.partitions.using.expressionstrue
=
4hive.vectorized.adaptor.suppress.evaluate.exceptionsfalse
5
.ipc.[port_number].decay-scheduler.decay-factor0.5
+
"dfs.federation.router.quota.enablefalse
G
!fs.AbstractFileSystem.viewfs.impl"org.apache.hadoop.fs.viewfs.ViewFs

*dfs.federation.router.secret.manager.classaorg.apache.hadoop.hdfs.server.federation.router.security.token.ZKDelegationTokenSecretManagerImpl

fs.ftp.host0.0.0.0
<
(fs.adl.oauth2.access.token.provider.typeClientCredential
M
Cyarn.nodemanager.linux-container-executor.nonsecure-mode.local-usernobody
$
hive.stats.column.autogathertrue
+
#fs.s3a.s3guard.ddb.background.sleep25ms
K
Byarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs86400
)
!hive.vectorized.execution.enabledtrue
&
hive.exec.copyfile.maxsize33554432
$
dfs.balancer.keytab.enabledfalse
3
"io.compression.codec.bzip2.librarysystem-native
$
hive.groupby.position.aliasfalse
$
dfs.client.retry.window.base3000

dfs.ha.zkfc.port8019
*
"hive.llap.io.allocator.preallocatetrue
1
)hive.materializedview.rebuild.incrementaltrue

hive.in.testfalse
7
0hive.metastore.aggregate.stats.cache.clean.until0.8
D
;yarn.nodemanager.resource.count-logical-processors-as-coresfalse

hive.stats.reliablefalse
&
hive.llap.lockmetrics.collectfalse
1
(yarn.timeline-service.client.best-effortfalse

hive.masking.algosha256
(
hive.hashtable.initialCapacity100000
+
"dfs.datanode.block-pinning.enabledfalse
3
'hive.query.results.cache.max.entry.size10485760
H
@yarn.resourcemanager.webapp.delegation-token-auth-filter.enabledtrue
6
.hive.test.vectorizer.suppress.fatal.exceptionstrue
1
io.seqfile.local.dir/tmp/hadoop-root/io/local
G
3yarn.nodemanager.webapp.rest-csrf.methods-to-ignoreGET,OPTIONS,HEAD
.
)ha.health-monitor.rpc.connect.max.retries1
5
.dfs.encrypt.data.transfer.cipher.key.bitlength128
M
Eyarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds.min3600
+
hive.server2.thrift.http.path
cliservice
'
yarn.app.mapreduce.am.log.levelINFO
(
dfs.datanode.sync.behind.writesfalse
%
dfs.balancer.dispatcherThreads200
1
*dfs.client.block.reader.remote.buffer.size512
 
hive.testing.short.logsfalse
F
>yarn.nodemanager.runtime.linux.runc.allowed-container-runtimesrunc
6
-hive.llap.external.client.use.hybrid.calendarfalse
$
hive.groupby.limit.extrasteptrue
;
/yarn.resourcemanager.zk-state-store.parent-path/rmstore
8
0hive.parquet.timestamp.legacy.conversion.enabledtrue
#
hive.server2.webui.use.sslfalse
"
hive.druid.kerberos.enabletrue
'
hadoop.ssl.enabled.protocolsTLSv1.2
,
'yarn.timeline-service.flowname.max-size0
!
yarn.client.failover-retries0
-
mapreduce.jobhistory.address0.0.0.0:10020
-
hive.server2.webui.xframe.value
SAMEORIGIN
 
tez.runtime.io.sort.factor10
=
7dfs.client.deadnode.detection.probe.suspectnode.threads10
4
.hive.server2.saml2.max.authentication.lifetime1h
$
dfs.datanode.address0.0.0.0:9866
›
-yarn.nodemanager.log-aggregation.policy.classjorg.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy
4
+dfs.client.deadnode.detection.idle.sleep.ms10000

dfs.ls.limit1000
-
%dfs.namenode.block.deletion.increment1000
$
ipc.client.connect.max.retries10
4
,yarn.nodemanager.container.stderr.tail.bytes4096
4
.hive.server2.thrift.client.retry.delay.seconds1s
3
-hive.driver.parallel.compilation.global.limit-1
4
#dfs.webhdfs.rest-csrf.custom-headerX-XSRF-HEADER
=
5dfs.namenode.corrupt.block.delete.immediately.enabledtrue
'
 hive.materializedview.fileformatORC
)
"mapreduce.job.heap.memory-mb.ratio0.8
,
#dfs.protected.subdirectories.enablefalse
a
)hive.tez.mapreduce.output.committer.class4org.apache.tez.mapreduce.committer.MROutputCommitter
!
hive.repl.stats.events.count5
9
1yarn.nodemanager.log-container-debug-info.enabledtrue
n
!mapreduce.task.profile.map.paramsI-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
F
@yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms10
?
7yarn.resourcemanager.nodemanagers.heartbeat-interval-ms1000
&
hive.limit.optimize.fetch.max50000
)
!hive.streaming.auto.flush.enabledtrue
-
%hive.syslog.input.format.file.pruningtrue
*
"hive.hdfs.encryption.shim.cache.ontrue
"
hive.test.fail.compactionfalse
7
.yarn.nodemanager.aux-services.manifest.enabledfalse

hive.exec.parallelfalse
5
-hive.optimize.shared.work.mapjoin.cache.reusetrue
*
%yarn.cluster.max-application-priority0
+
%dfs.disk.balancer.plan.valid.interval1d
\
hive.service.metrics.class>org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics
 
hive.udtf.auto.progressfalse

hive.archive.enabledfalse
!
fs.trash.checkpoint.interval0
f
_hive.tmp_table_spaceM/opt/hive/scratch_dir/root/00f712e8-ce88-47df-9938-d3857344e739/_tmp_space.db
F
>yarn.nodemanager.resource.memory.cgroups.soft-limit-percentage90.0
,
dfs.journalnode.http-address0.0.0.0:8480
=
!yarn.app.mapreduce.am.staging-dir/tmp/hadoop-yarn/staging
+
"hive.parquet.write.int64.timestampfalse
5
+yarn.nm.liveness-monitor.expiry-interval-ms600000
,
$hive.convert.join.bucket.mapjoin.teztrue

fs.s3a.select.enabledtrue
5
*yarn.nodemanager.health-checker.timeout-ms1200000
6
/hive.optimize.bi.rewrite.percentile_disc.sketchkll
#
ipc.client.connect.timeout20000
)
 hive.acid.createtable.softdeletefalse
0
'hive.llap.daemon.download.permanent.fnsfalse
#
hive.compactor.gather.statstrue
<
yarn.nodemanager.local-dirs/tmp/hadoop-root/nm-local-dir
0
(yarn.scheduler.configuration.store.classfile
0
!fs.s3a.committer.staging.tmp.pathtmp/staging
*
!yarn.nodemanager.recovery.enabledfalse
-
%hive.test.mapjoin.full.outer.overridenone
-
'hive.server2.webui.max.historic.queries25
0
(dfs.block.scanner.volume.join.timeout.ms5000

hive.server2.use.SSLfalse
8
0hive.vectorized.execution.reducesink.new.enabledtrue
9
2yarn.nodemanager.resource.pcores-vcores-multiplier1.0
/
*hive.compactor.history.retention.attempted2
0
*hadoop.kerberos.min.seconds.before.relogin60

dfs.image.compressfalse
4
+hive.describe.partitionedtable.ignore.statsfalse
,
 hive.mapjoin.smalltable.filesize25000000
_
Vdfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction0.75f
(
#hive.xprod.mapjoin.small.table.rows1
~
(dfs.federation.router.store.driver.classRorg.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl
:
3dfs.namenode.edit.log.autoroll.multiplier.threshold0.5
/
&hadoop.security.group.mapping.ldap.sslfalse
 
hive.server2.webui.port10002
$
fs.defaultFShdfs://namenode:8020
7
2hive.compactor.initiator.failed.compacts.threshold2
U
Myarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage90.0
O
Fyarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabledfalse
/
)hive.mapjoin.hybridgrace.minnumpartitions16
)
 dfs.provided.acls.import.enabledfalse
.
%dfs.namenode.read.considerStorageTypefalse
(
 hive.map.aggr.hash.min.reduction0.99
)
$hive.repl.retain.prev.dump.dir.count3
"
hive.cbo.costmodel.cpu0.000001
/
&yarn.webapp.filter-entity-list-by-userfalse
Œ
0yarn.log-aggregation.file-controller.TFile.classXorg.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController
)
dfs.namenode.http-address0.0.0.0:9870
š
6hadoop.security.crypto.codec.classes.aes.ctr.nopadding`org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec
3
+hive.exec.dynamic.partition.type.conversiontrue
J
_hive.local.session.path./tmp/root/00f712e8-ce88-47df-9938-d3857344e739
O
fs.s3a.metadatastore.impl2org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore
)
 hive.insert.into.multilevel.dirsfalse

hive.txn.read.lockstrue
$
hive.hmshandler.retry.attempts10
(
hadoop.ssl.server.confssl-server.xml
8
1hive.compactor.initiator.duration.update.interval60s
3
"mapreduce.jobhistory.admin.address0.0.0.0:10033
2
-dfs.namenode.startup.delay.block.deletion.sec0
0
(hive.server2.operation.log.cleanup.delay300s
&
!fs.s3a.connection.request.timeout0
5
+yarn.nodemanager.health-checker.interval-ms600000
 
hive.llap.execution.modenone
,
#hive.llap.enable.grace.join.in.llapfalse
‰
hive.conf.restricted.listë
hive.security.authenticator.manager,hive.security.authorization.manager,hive.security.metastore.authorization.manager,hive.security.metastore.authenticator.manager,hive.users.in.admin.role,hive.server2.xsrf.filter.enabled,hive.security.authorization.enabled,hive.distcp.privileged.doAs,hive.server2.authentication.ldap.baseDN,hive.server2.authentication.ldap.url,hive.server2.authentication.ldap.Domain,hive.server2.authentication.ldap.groupDNPattern,hive.server2.authentication.ldap.groupFilter,hive.server2.authentication.ldap.userDNPattern,hive.server2.authentication.ldap.userFilter,hive.server2.authentication.ldap.groupMembershipKey,hive.server2.authentication.ldap.userMembershipKey,hive.server2.authentication.ldap.groupClassKey,hive.server2.authentication.ldap.customLDAPQuery,hive.server2.service.users,hive.server2.graceful.stop.timeout,hive.privilege.synchronizer,hive.privilege.synchronizer.interval,hive.query.max.length,hive.druid.broker.address.default,hive.druid.coordinator.address.default,hikaricp.,hadoop.bin.path,yarn.bin.path,hive.driver.parallel.compilation.global.limit,hive.zookeeper.ssl.keystore.location,hive.zookeeper.ssl.keystore.password,hive.zookeeper.ssl.truststore.location,hive.zookeeper.ssl.truststore.password,_hive.local.session.path,_hive.hdfs.session.path,_hive.tmp_table_space,_hive.local.session.path,_hive.hdfs.session.path,_hive.tmp_table_space
2
-yarn.app.mapreduce.task.container.log.backups0
5
,mapreduce.reduce.shuffle.fetch.retry.enabledfalse

dfs.heartbeat.interval3s
 
hive.auto.progress.timeout0s
"
hive.llap.io.threadpool.size10
$
hive.druid.select.threshold10000

dfs.datanode.lock.fairtrue
-
hive.exec.scratchdir/opt/hive/scratch_dir
7
/hive.tez.dynamic.semijoin.reduction.multicolumntrue
[
0hadoop.http.authentication.signature.secret.file'/root/hadoop-http-auth-signature-secret
C
5mapreduce.jobhistory.webapp.xfs-filter.xframe-options
SAMEORIGIN
9
1yarn.nodemanager.log-aggregation.compression-typenone

hive.scratchdir.lockfalse
I
@yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms10000
6
yarn.nodemanager.log-dirs/opt/hadoop/logs/userlogs
<
4yarn.nodemanager.container-retry-minimum-interval-ms1000
!
hive.server.tcp.keepalivetrue
w
)mapreduce.jobhistory.recovery.store.classJorg.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService
†
5yarn.nodemanager.amrmproxy.interceptor-class.pipelineMorg.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor
'
hive.zookeeper.kerberos.enabledtrue
H
hive.input.format3org.apache.hadoop.hive.ql.io.CombineHiveInputFormat

ipc.client.low-latencyfalse
/
'hive.repl.run.data.copy.tasks.on.targettrue
/
'yarn.webapp.enable-rest-app-submissionstrue
-
#hive.compactor.cleaner.run.interval5000ms
%
yarn.nodemanager.address	0.0.0.0:0
%
hive.repl.dump.metadata.onlyfalse
/
*dfs.federation.router.connection.pool-size1
&
hive.server2.webui.show.statsfalse
-
%hive.vectorized.reuse.scratch.columnstrue

mapreduce.job.reduces-1
:
1hive.metastore.schema.verification.record.versionfalse
/
(hive.llap.task.scheduler.timeout.seconds60s
.
yarn.timeline-service.address0.0.0.0:10200
)
hive.support.quoted.identifierscolumn
f
1yarn.resourcemanager.configuration.provider-class1org.apache.hadoop.yarn.LocalConfigurationProvider
-
$hive.optimize.filter.stats.reductionfalse
.
%hadoop.registry.zk.session.timeout.ms60000

tfile.io.chunk.size1048576
8
/yarn.timeline-service.http-cross-origin.enabledfalse
3
+ha.health-monitor.sleep-after-disconnect.ms1000
 
hive.typecheck.on.inserttrue
)
"dfs.content-summary.sleep-microsec500
4
+hive.metastore.authorization.storage.checksfalse
K
Eyarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs20
-
#dfs.datanode.directoryscan.interval21600s
2
)hadoop.http.authentication.token.validity36000
4
(mapreduce.jobhistory.cleaner.interval-ms86400000
<
4dfs.namenode.datanode.registration.ip-hostname-checktrue
/
&hive.server2.clear.dangling.scratchdirfalse
?
:yarn.nodemanager.opportunistic-containers-max-queue-length0
+
#dfs.namenode.blockreport.queue.size1024
#
hive.test.fail.heartbeaterfalse
*
!datanucleus.schema.validateTablesfalse
+
fs.ftp.transfer.modeBLOCK_TRANSFER_MODE

fs.s3a.executor.capacity16
G
3yarn.nodemanager.resource-plugins.gpu.docker-pluginnvidia-docker-v1
#
hive.optimize.countdistincttrue
@
fs.wasb.impl0org.apache.hadoop.fs.azure.NativeAzureFileSystem
V
*fs.viewfs.overload.scheme.target.http.impl(org.apache.hadoop.fs.http.HttpFileSystem
/
!hive.llap.daemon.web.xframe.value
SAMEORIGIN
8
.yarn.timeline-service.http-authentication.typesimple
B
9dfs.namenode.snapshot.skip.capture.accesstime-only-changefalse
*
dfs.balancer.max-iteration-time1200000
+
"hadoop.prometheus.endpoint.enabledfalse
.
$yarn.dispatcher.drain-events.timeout300000
&
ipc.client.bind.wildcard.addrfalse
"
hive.optimize.correlationfalse
)
#yarn.log-aggregation.retain-seconds-1
7
/mapreduce.job.complete.cancel.delegation.tokenstrue
'
fs.s3a.multiobjectdelete.enabletrue
>
9yarn.resourcemanager.placement-constraints.retry-attempts3
4
/mapreduce.shuffle.connection-keep-alive.timeout5
-
(yarn.scheduler.minimum-allocation-vcores1
3
*fs.s3a.s3guard.ddb.throttle.retry.interval100ms
/
%hive.vectorized.groupby.checkinterval100000
.
(yarn.timeline-service.client.max-retries30
!
nfs.exports.allowed.hosts* rw
!
dfs.client.mmap.cache.size256
"
hive.cli.print.current.dbfalse
*
%dfs.client.max.block.acquire.failures3
]
Vdfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction0.6
&
orc.force.positional.evolutiontrue
:
2dfs.client.retry.interval-ms.get-last-block-length4000
)
!ipc.client.connect.retry.interval1000
'
dfs.namenode.checkpoint.txns1000000
Y
"hadoop.security.secure.random.impl3org.apache.hadoop.crypto.random.OpensslSecureRandom
2
,yarn.nodemanager.container-metrics.period-ms-1
Z
*fs.viewfs.overload.scheme.target.hdfs.impl,org.apache.hadoop.hdfs.DistributedFileSystem
#
hive.llap.auto.enforce.treetrue
1
)dfs.namenode.list.openfiles.num.responses1000
%
hive.metastore.stats.ndv.tuner0.0
'
 hive.direct.sql.max.query.length100
%
hive.server2.thrift.bind.hosthive
9
3yarn.timeline-service.client.fd-flush-interval-secs10
4
,hive.server2.tez.initialize.default.sessionstrue

hive.txn.max.open.batch1000
0
(hive.server2.close.session.on.disconnecttrue
%
hive.compactor.check.interval300s
#
hive.optimize.ppd.windowingtrue
,
yarn.resourcemanager.address0.0.0.0:8032

file.stream-buffer-size4096
V
(ipc.[port_number].identity-provider.impl*org.apache.hadoop.ipc.UserIdentityProvider
'
dfs.journalnode.sync.interval120000
6
0yarn.resourcemanager.nodemanager-connect-retries10

fs.azure.secure.modefalse
:
3yarn.nodemanager.logaggregation.threadpool-size-max100
 
ipc.client.idlethreshold4000
-
$dfs.http.client.retry.policy.enabledfalse
)
!dfs.quota.by.storage.type.enabledtrue
:
*yarn.nodemanager.collector-service.address0.0.0.0:8048
H
fs.abfss.impl7org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem
6
&yarn.sharedcache.client-server.address0.0.0.0:8045
&
hive.start.cleanup.scratchdirfalse
-
&hive.server2.async.exec.keepalive.time10s
;
6dfs.namenode.replication.work.multiplier.per.iteration2
&
hive.exec.orc.split.strategyHYBRID
H
hive.default.serde2org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
$
hive.optimize.listbucketingfalse
"
hive.server2.webui.host0.0.0.0
E
4yarn.timeline-service.webapp.rest-csrf.custom-headerX-XSRF-Header
,
hive.query.result.fileformatSequenceFile
#
dfs.journalnode.enable.synctrue
Ž
Ayarn.nodemanager.linux-container-executor.resources-handler.classIorg.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler
1
,dfs.client.retry.times.get-last-block-length3
=
4yarn.timeline-service.app-collector.linger-period.ms60000
*
"hive.optimize.constant.propagationtrue
1
)dfs.namenode.storageinfo.defragment.ratio0.75
$
hive.transform.escape.inputfalse
6
/dfs.client.read.shortcircuit.streams.cache.size256
0
'hive.orc.splits.ms.footer.cache.enabledfalse

file.replication1
2
*mapreduce.reduce.skip.proc-count.auto-incrtrue
%
yarn.federation.cache-ttl.secs300
3
*hive.metastore.client.cache.v2.recordStatsfalse
,
&dfs.datanode.processcommands.threshold2s
+
"hive.server2.graceful.stop.timeout1800s
3
metastore.warehouse.dir/opt/hive/data/warehouse

ipc.server.reuseaddrtrue
=
5yarn.resourcemanager.work-preserving-recovery.enabledtrue
#
dfs.image.transfer.timeout60000
'
hive.jdbc.pushdown.safe.enablefalse
B
io.compression.codecs)org.apache.hadoop.io.compress.SnappyCodec

	nfs.wtmax1048576
6
.yarn.resourcemanager.webapp.ui-actions.enabledtrue
+
#fs.s3a.connection.establish.timeout5000
/
*hive.metastore.hbase.file.metadata.threads1

hive.rework.mapredworkfalse
S
Nyarn.nodemanager.disk-health-checker.min-free-space-per-disk-watermark-high-mb0
/
)hive.metastore.client.connect.retry.delay1s

dfs.stream-buffer-size4096
8
2dfs.federation.router.client.mount-status.time-out1s
#
fs.s3a.multipart.purge.age86400
8
2yarn.resourcemanager.scheduler.client.thread-count50
4
+yarn.resourcemanager.auto-update.containersfalse
$
ipc.maximum.data.length	134217728
$
tfile.fs.input.buffer.size262144
#
hive.txn.xlock.mergeinsertfalse
6
.hive.repl.retain.custom.db.locations.on.targettrue
!
hive.limit.row.max.size100000
7
.hive.metastore.thrift.compact.protocol.enabledfalse
x
0dfs.federation.router.file.resolver.client.classDorg.apache.hadoop.hdfs.server.federation.resolver.MountTableResolver
9
-hive.auto.convert.join.noconditionaltask.size10000000
>
9yarn.resourcemanager.zk-delegation-token-node.split-index0
B
"fs.AbstractFileSystem.webhdfs.implorg.apache.hadoop.fs.WebHdfs

hive.join.cache.size25000

ftp.bytes-per-checksum512

dfs.pipeline.ecnfalse
1
)hadoop.workaround.non.threadsafe.getpwuidtrue
!
dfs.user.home.dir.prefix/user
8
2dfs.namenode.gc.time.monitor.observation.window.ms1m
I
?dfs.storage.policy.satisfier.datanode.cache.refresh.interval.ms300000
6
'hive.auto.convert.join.shuffle.max.size10000000000
"
mapreduce.task.profile.maps0-2
)
 hive.driver.parallel.compilationfalse
7
0hive.materializedview.rebuild.incremental.factor0.1
/
&mapreduce.shuffle.ssl.file.buffer.size65536

hive.skewjoin.key100000
.
&datanucleus.rdbms.initializeColumnInfoNONE
.
(dfs.namenode.redundancy.interval.seconds3s
:
*yarn.timeline-service.webapp.https.address0.0.0.0:8190
2
-dfs.datanode.transfer.socket.recv.buffer.size0
Y
yarn.registry.classBorg.apache.hadoop.registry.client.impl.FSRegistryOperationsService
1
(yarn.nodemanager.resource.memory.enabledfalse
/
(dfs.datanode.lock-reporting-threshold-ms300
/
"yarn.app.mapreduce.am.command-opts	-Xmx1024m
.
&hive.llap.cache.allow.synthetic.fileidtrue
/
*dfs.datanode.data.transfer.bandwidthPerSec0
g
+fs.viewfs.overload.scheme.target.swift.impl8org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem
2
)dfs.http.client.failover.sleep.max.millis15000

hive.llap.plugin.acl*
3
*dfs.client.ignore.namenode.default.kms.urifalse
E
;yarn.nodemanager.node-attributes.provider.fetch-interval-ms600000
(
hive.hmshandler.retry.interval2000ms
R
Lyarn.resourcemanager.opportunistic.max.container-allocation.per.am.heartbeat-1
$
hadoop.registry.zk.root	/registry
!
dfs.balancer.moverThreads1000
1
$hive.server2.thrift.max.message.size	104857600
#
dfs.client.retry.max.attempts10
f
#yarn.client.failover-proxy-provider?org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider
M
Gyarn.resourcemanager.delegation-token-renewer.thread-retry-max-attempts10
+
"yarn.nodemanager.amrmproxy.enabledfalse
2
*yarn.nodemanager.remote-app-log-dir-suffixlogs
F
,hive.metastore.archive.intermediate.original_INTERMEDIATE_ORIGINAL
-
'dfs.datanode.restart.replica.expiration50
#
dfs.namenode.edits.dir.minimum1

nfs.mountd.port4242
.
&mapreduce.reduce.merge.inmem.threshold1000
(
dfs.webhdfs.netty.low.watermark32768
4
,hive.vectorized.use.vector.serde.deserializetrue
.
(fs.s3a.select.input.csv.record.delimiter\n

dfs.batched.ls.limit100
)
$hive.scheduled.queries.max.executors4

fs.s3a.retry.limit7
)
!tez.runtime.shuffle.merge.percent0.66
+
"dfs.namenode.state.context.enabledfalse
!
hive.compute.splits.in.amtrue
'
hive.compactor.worker.timeout86400s
"
hive.exec.schema.evolutiontrue
3
.yarn.nodemanager.localizer.client.thread-count5
3
-yarn.sharedcache.uploader.server.thread-count50
2
*hive.direct.sql.max.elements.values.clause1000
2
(hive.repl.authorization.provider.serviceranger
9
/dfs.namenode.storageinfo.defragment.interval.ms600000
 
dfs.namenode.fslock.fairtrue
*
dfs.blockreport.split.threshold1000000
,
$dfs.datanode.balance.bandwidthPerSec100m
&
stream.stderr.reporter.enabledtrue
0
)hive.repl.external.client.connect.timeout10s
0
%hive.druid.indexer.partition.size.max5000000

hive.llap.auto.authfalse
#
dfs.balancer.service.interval5m
X
 hive.metastore.schema.info.class4org.apache.hadoop.hive.metastore.MetaStoreSchemaInfo
$
dfs.default.chunk.view.size32768
.
(dfs.disk.balancer.plan.threshold.percent10
4
*mapreduce.jobhistory.datestring.cache.size200000
$
yarn.acl.reservation-enablefalse

hive.txn.stats.enabledtrue
.
(mapreduce.jobhistory.loadedjob.tasks.max-1
*
%yarn.app.mapreduce.client.max-retries3
$
fs.azure.local.sas.key.modefalse
I
@yarn.nodemanager.runtime.linux.docker.host-pid-namespace.allowedfalse
#
ipc.server.listen.queue.size256
?
6yarn.nodemanager.resource.detect-hardware-capabilitiesfalse
G
Bdfs.client.block.write.replace-datanode-on-failure.min-replication0
H
@yarn.nodemanager.runtime.linux.docker.allowed-container-runtimesrunc
M
Gyarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size10

hive.create.as.acidfalse
z
$yarn.resourcemanager.scheduler.classRorg.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
/
&dfs.block.access.token.protobuf.enablefalse

yarn.is.miniclusterfalse
+
"hive.llap.daemon.yarn.shuffle.port15551
8
/ha.failover-controller.cli-check.rpc-timeout.ms20000
1
(hive.metastore.stats.ndv.densityfunctionfalse
%
hive.druid.passiveWaitTimeMs30000
"
dfs.encrypt.data.transferfalse
)
#hive.load.dynamic.partitions.thread15
$
hive.tez.exec.print.summaryfalse
(
hive.exec.compress.intermediatefalse
&
hive.parquet.infer.binary.asbinary
!
dfs.mover.keytab.enabledfalse
j
hive.metastore.expression.proxyGorg.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore
6
&yarn.resourcemanager.scheduler.address0.0.0.0:8030
Q
Hyarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size10000
K
hive.script.recordreader/org.apache.hadoop.hive.ql.exec.TextRecordReader
7
.dfs.federation.router.connection.pool.clean.ms60000
,
#hive.repl.handle.ranger.deny.policyfalse
7
.hive.metastore.thrift.framed.transport.enabledfalse
,
#hive.server2.tez.queue.access.checkfalse
&
hadoop.service.shutdown.timeout30s
"
mapreduce.reduce.log.levelINFO
8
0hive.vectorized.execution.reduce.groupby.enabledtrue

hive.stats.dbclassfs
/
*mapreduce.job.cache.limit.max-resources-mb0
H
Byarn.resourcemanager.opportunistic-container-allocation.nodes-used10
:
2dfs.federation.router.monitor.localnamenode.enabletrue
:
3hive.llap.external.splits.temp.table.storage.formatorc
(
 hive.llap.io.row.wrapper.enabledtrue
/
'hive.llap.io.proactive.eviction.enabledtrue
4
/dfs.federation.router.client.retry.max.attempts3
'
hive.exec.rcfile.use.sync.cachetrue
Ê
+dfs.webhdfs.acl.provider.permission.patternš^(default:)?(user|group|mask|other):[[A-Za-z_][A-Za-z0-9._-]]*:([rwx-]{3})?(,(default:)?(user|group|mask|other):[[A-Za-z_][A-Za-z0-9._-]]*:([rwx-]{3})?)*$
+
"dfs.datanode.use.datanode.hostnamefalse
(
yarn.resourcemanager.ha.enabledfalse
1
+yarn.dispatcher.cpu-monitor.samples-per-min60

hive.fileformat.checktrue
4
.fs.s3a.select.input.csv.quote.escape.character\\
.
%hive.avro.proleptic.gregorian.defaultfalse
3
*dfs.namenode.lock.detailed-metrics.enabledfalse
)
dfs.namenode.rpc-addressnamenode:8020
)
 hive.stats.join.ndv.readjustmentfalse

dfs.reformat.disabledfalse

hive.repl.cm.enabledfalse
+
&hive.server2.thrift.client.retry.limit1
9
0hive.server2.thrift.resultset.serialize.in.tasksfalse
,
&dfs.client.write.max-packets-in-flight80
)
 hadoop.http.cross-origin.enabledfalse
4
"dfs.https.server.keystore.resourcessl-server.xml
*
yarn.workflow-id.tag-prefixworkflowid:
$
hive.exec.infer.bucket.sortfalse
"
hive.stats.use.bitvectorsfalse
C
;yarn.resourcemanager.state-store.max-completed-applications1000
.
%hive.exec.submit.local.task.via.childfalse
5
-yarn.resourcemanager.application-https.policyNONE
'
hive.constraint.notnull.enforcetrue
F
3hive.cluster.delegation.token.store.zookeeper.znode/hivedelegation
'
fs.s3a.ssl.channel.modedefault_jsse
 
hive.query.timeout.seconds0s
-
&hive.service.metrics.hadoop2.frequency30s
?
6hive.server2.materializedviews.registry.refresh.period1500s
.
(hive.tez.unordered.output.buffer.size.mb-1
)
fs.s3a.buffer.dir/tmp/hadoop-root/s3a
4
+mapreduce.reduce.shuffle.retry-delay.max.ms60000
,
'yarn.app.mapreduce.shuffle.log.limit.kb0
5
-mapreduce.client.progressmonitor.pollinterval1000

hive.in.iceberg.testfalse
*
!hive.llap.task.time.print.summaryfalse
3
)dfs.namenode.retrycache.expirytime.millis600000
8
1hive.mapjoin.followby.map.aggr.hash.percentmemory0.3
%
dfs.datanode.scan.period.hours504
/
%mapreduce.jobhistory.move.interval-ms180000
&
dfs.datanode.disk.check.min.gap15m
2
+dfs.namenode.fs-limits.max-component-length255
2
)yarn.timeline-service.hbase-schema.prefixprod.
G
Ayarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds-1
$
hive.variable.substitute.depth40
t
'yarn.timeline-service.state-store-classIorg.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore
8
#hadoop.security.crypto.cipher.suiteAES/CTR/NoPadding
H
?yarn.resourcemanager.opportunistic-container-allocation.enabledfalse
-
&hive.optimize.sampling.orderby.percent0.1
 
hive.ignore.mapjoin.hinttrue

dfs.ha.tail-edits.period60s
K
Byarn.timeline-service.generic-application-history.max-applications10000
0
(hive.syslog.input.format.file.time.slice300s
(
dfs.client.retry.policy.enabledfalse
0
*ipc.[port_number].weighted-cost.lockshared10
b
5hadoop.security.group.mapping.ldap.search.filter.user)(&(objectClass=user)(sAMAccountName={0}))
:
dfs.namenode.edits.dir file:///tmp/hadoop-root/dfs/name
,
"hive.groupby.mapaggr.checkinterval100000
*
#javax.jdo.option.ConnectionUserNameAPP
@
5hive.llap.task.scheduler.node.reenable.max.timeout.ms10000ms

hive.max.open.txns100000
=
6dfs.namenode.decommission.max.concurrent.tracked.nodes100
4
,hive.auto.convert.sortmerge.join.reduce.sidetrue
µ
"hive.script.operator.env.blacklistŽhive.txn.valid.txns,hive.txn.tables.valid.writeids,hive.txn.valid.writeids,hive.script.operator.env.blacklist,hive.repl.current.table.write.id
 
ipc.server.log.slow.rpcfalse

hive.in.tez.testfalse
g
yarn.sharedcache.store.classGorg.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore
7
.yarn.app.mapreduce.am.webapp.https.client.authfalse
:
3dfs.namenode.list.reencryption.status.num.responses100
0
%dfs.journalnode.edit-cache-size.bytes1048576
@
7dfs.namenode.decommission.backoff.monitor.pending.limit10000
(
#hive.llap.nodehealthchecks.maxnodes1
#
hive.cli.print.escape.crlffalse
*
!dfs.ha.automatic-failover.enabledfalse
)
 hive.trigger.validation.interval500ms
–
/yarn.resourcemanager.scheduler.monitor.policiescorg.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy
z
-yarn.router.webapp.interceptor-class.pipelineIorg.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST
$
dfs.use.dfs.network.topologytrue
)
!hive.hook.proto.rollover-interval600s
L
Dyarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds3600
w
tez.staging-dirdhdfs://namenode:8020/opt/hive/scratch_dir/root/_tez_session_dir/eabea070-91ec-4395-be55-fb7f7daecd89
6
.dfs.namenode.write-lock-reporting-threshold-ms5000
'
hive.transpose.aggr.join.uniquetrue

fs.s3a.block.size32M
/
&dfs.namenode.avoid.read.stale.datanodefalse
2
-mapreduce.job.end-notification.retry.attempts0

hive.cbo.cnf.maxnodes-1
)
"hive.vectorized.adaptor.usage.modeall
C
yarn.ipc.rpc.class-org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
.
&dfs.namenode.lease-recheck-interval-ms2000
C
<dfs.client.block.write.locateFollowingBlock.initial.delay.ms400

tez.counters.max120
"
dfs.mover.retry.max.attempts10
C
;yarn.nodemanager.resource-plugins.fpga.allowed-fpga-devicesauto
#
mapreduce.job.ubertask.maxmaps9
G
?yarn.nodemanager.runtime.linux.docker.default-container-networkhost

hive.tez.log.levelINFO
F
Ayarn.nodemanager.runtime.linux.docker.userremapping-uid-threshold1
O
Gyarn.nodemanager.disk-health-checker.disk-utilization-threshold.enabledtrue

hive.merge.mapfilestrue
4
+hive.server2.historic.operation.log.enabledfalse
+
%hive.metastore.client.socket.lifetime0s
=
3hive.server2.authentication.ldap.groupMembershipKeymember
E
:yarn.nodemanager.node-attributes.provider.fetch-timeout-ms1200000

hive.repl.retry.jitter30s
2
*hive.mapjoin.hybridgrace.memcheckfrequency1024
(
 hive.exec.counters.pull.interval1000
,
'hive.server2.webui.cors.allowed.origins*
4
/hadoop.security.group.mapping.ldap.num.attempts3
7
0dfs.namenode.lazypersist.file.scrub.interval.sec300
U
$yarn.scheduler.configuration.fs.path-file:///tmp/hadoop-root/yarn/system/schedconf
X
*fs.viewfs.overload.scheme.target.o3fs.impl*org.apache.hadoop.fs.ozone.OzoneFileSystem
G
 fs.AbstractFileSystem.abfss.impl#org.apache.hadoop.fs.azurebfs.Abfss
?
1yarn.nodemanager.webapp.xfs-filter.xframe-options
SAMEORIGIN
+
yarn.nodemanager.keytab/etc/krb5.keytab
T
hive.downloaded.resources.dir3/tmp/00f712e8-ce88-47df-9938-d3857344e739_resources

nfs.dump.dir/tmp/.hdfs-nfs
D
6yarn.timeline-service.webapp.xfs-filter.xframe-options
SAMEORIGIN
(
 yarn.timeline-service.ttl-enabletrue
o
Oyarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.hdfs-hash-file/runc-root/image-tag-to-hash
$
mapreduce.reduce.skip.maxgroups0
1
(hive.lazysimple.extended_boolean_literalfalse
&
hive.error.on.empty.partitionfalse
,
#hive.orc.splits.include.file.footerfalse
>
8ipc.[port_number].decay-scheduler.metrics.top.user.count10
)
hadoop.bin.path/opt/hadoop/bin/hadoop
;
2yarn.nodemanager.container-log-monitor.interval-ms60000

seq.io.sort.factor100
5
.dfs.namenode.checkpoint.check.quiet-multiplier1.5
5
-yarn.nodemanager.resource-monitor.interval-ms3000
+
"dfs.client.read.use.cache.priorityfalse
+
&fs.s3a.s3guard.consistency.retry.limit7
/
*dfs.client.refresh.read-block-locations.ms0
F
mapreduce.jobhistory.done-dir%/tmp/hadoop-yarn/staging/history/done
7
.hadoop.security.instrumentation.requires.adminfalse
8
/hive.autogen.columnalias.prefix.includefuncnamefalse
!
hive.server2.thrift.port10000
4
.dfs.namenode.max-lock-hold-to-release-lease-ms25
1
,hive.server2.limit.connections.per.ipaddress0
#
dfs.client.block.write.retries3
=
8ha.failover-controller.graceful-fence.connection.retries1

httpfs.buffer.size4096
-
#dfs.namenode.safemode.threshold-pct0.999f
)
!hive.stats.deserialization.factor10.0
9
1yarn.nodemanager.remote-app-log-dir-include-oldertrue
8
0dfs.federation.router.default.nameservice.enabletrue
&
hive.llap.io.cache.deletedeltasall
"
hive.acid.truncate.usebasetrue
$
hive.txn.operational.properties1
.
(mapreduce.client.submit.file.replication10
-
%javax.jdo.option.NonTransactionalReadtrue
i
*dfs.namenode.edits.journal-plugin.qjournal;org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager
(
hive.repl.bootstrap.acid.tablesfalse
2
+hive.compactor.obsolete.delta.dir.threshold200

hive.llap.daemon.rpc.port0
!
hive.optimize.bi.enabledfalse
6
/dfs.namenode.reconstruction.pending.timeout-sec300
)
yarn.timeline-service.hostname0.0.0.0
 
io.skip.checksum.errorsfalse
I
9yarn.resourcemanager.nm-container-queuing.load-comparatorQUEUE_LENGTH
3
+hive.vectorized.use.vectorized.input.formattrue
:
2hive.security.authorization.kerberos.use.shortnametrue
.
&hive.display.partition.cols.separatelytrue

file.blocksize67108864
=
5hive.metastore.disallow.incompatible.col.type.changestrue

hive.test.modefalse
V
'hadoop.rpc.socket.factory.class.default+org.apache.hadoop.net.StandardSocketFactory
2
)hive.metastore.client.cache.stats.enabledfalse
4
hive.metastore.warehouse.dir/user/hive/warehouse
D
#fs.AbstractFileSystem.swebhdfs.implorg.apache.hadoop.fs.SWebHdfs
.
(yarn.resourcemanager.client.thread-count50
(
#hive.mapjoin.hashtable.load.threads2
#
hive.querylog.location	/tmp/root
,
$yarn.sharedcache.cleaner.period-mins1440
6
/hive.scheduled.queries.executor.idle.sleep.time60s
9
1mapreduce.job.end-notification.max.retry.interval5000
<
3yarn.resourcemanager.delegation-token.always-cancelfalse
2
)mapreduce.jobhistory.always-scan-user-dirfalse
$
hive.exec.job.debug.timeout30000
,
%hive.notification.event.poll.interval60s
/
&hive.transactional.concatenate.noblockfalse
.
)yarn.app.mapreduce.am.resource.cpu-vcores1
[
)hive.cluster.delegation.token.store.class.org.apache.hadoop.hive.thrift.MemoryTokenStore
%
hive.repl.rootdir/user/root/repl/
8
0dfs.namenode.redundancy.queue.restart.iterations2400
E
=hive.optimize.join.disjunctive.transitive.predicates.pushdowntrue
G
=yarn.resourcemanager.placement-constraints.algorithm.iteratorSERIAL
4
#dfs.federation.router.https-address0.0.0.0:50072
]
-fs.viewfs.overload.scheme.target.webhdfs.impl,org.apache.hadoop.hdfs.web.WebHdfsFileSystem
5
/fs.s3a.select.output.csv.quote.escape.character\\
.
%dfs.qjournal.start-segment.timeout.ms20000
5
(hive.materializedview.rewriting.strategy	heuristic
)
yarn.sharedcache.root-dir/sharedcache
7
.hadoop.security.groups.cache.background.reloadfalse
8
/mapreduce.reduce.shuffle.fetch.retry.timeout-ms30000

dfs.namenode.max.objects0

dfs.bytes-per-checksum512
6
.hadoop.security.credential.clear-text-fallbacktrue
)
!dfs.datanode.max.transfer.threads4096
+
$dfs.block.access.key.update.interval600
N
hive.mapred.partitioner3org.apache.hadoop.hive.ql.io.DefaultHivePartitioner

hive.async.log.enabledtrue
,
&hive.metastore.limit.partition.request-1

mapreduce.map.memory.mb-1
E
>yarn.nodemanager.runtime.linux.runc.layer-mounts-interval-secs600
)
 hive.llap.io.vrb.queue.limit.max50000
S
)fs.viewfs.overload.scheme.target.s3a.impl&org.apache.hadoop.fs.s3a.S3AFileSystem
$
tez.am.maxtaskfailures.per.node3
+
!mapreduce.jobhistory.jhist.formatbinary
&
hive.entity.capture.transformfalse
:
2dfs.federation.router.client.allow-partial-listingtrue
,
$yarn.scheduler.minimum-allocation-mb1024
:
net.topology.impl%org.apache.hadoop.net.NetworkTopology
&
hive.allow.udf.load.on.demandfalse
-
(ipc.[port_number].weighted-cost.lockfree1

hive.default.nulls.lasttrue
'
hive.acid.direct.insert.enabledtrue
@
;ha.failover-controller.active-standby-elector.zk.op.retries3
@
fs.AbstractFileSystem.ftp.implorg.apache.hadoop.fs.ftp.FtpFs
'
"mapreduce.job.running.reduce.limit0
+
&dfs.client.hedged.read.threadpool.size0
1
'dfs.namenode.heartbeat.recheck-interval300000
'
hive.mr.compactor.gather.statsfalse
+
#yarn.nodemanager.vmem-check-enabledtrue
v
hive.metastore.filter.hookXorg.apache.hadoop.hive.ql.security.authorization.plugin.AuthorizationMetaStoreFilterHook
&
hive.vectorized.if.expr.modebetter
1
*dfs.http.client.failover.sleep.base.millis500
7
+dfs.namenode.delegation.key.update-interval86400000
8
&hive.server2.global.init.file.location/opt/hive/conf
'
hadoop.rpc.protectionauthentication
 
fs.permissions.umask-mode022
#
hive.tez.bloom.filter.factor1.0
-
(hive.llap.daemon.am-reporter.max.threads4

fs.scheme.classdfs
%
hive.metastore.try.direct.sqltrue

fs.s3a.connection.maximum48
#
hive.metastore.failure.retries1

fs.s3a.paging.maximum5000
"
hive.hbase.generatehfilesfalse

hive.stats.join.factor1.1
(
ipc.maximum.response.length	134217728
/
&hadoop.shell.missing.defaultFs.warningfalse
,
#hive.repl.atlas.client.read.timeout7200s
.
$hive.localize.resource.wait.interval5000ms

tez.am.modify-aclsroot

hive.exim.test.modefalse
$
hive.metastore.sasl.enabledfalse
:
.yarn.nodemanager.container-localizer.java.opts-Xmx256m
A
9dfs.client.block.write.replace-datanode-on-failure.enabletrue
$
hive.strict.checks.bucketingtrue

hive.rpc.query.plantrue
*
 dfs.namenode.top.windows.minutes1,5,25
0
'dfs.client.use.legacy.blockreader.localfalse
E
.dfs.webhdfs.rest-csrf.browser-useragents-regex^Mozilla.*,^Opera.*
&
hive.tez.bucket.pruning.compattrue
>
"hive.query.results.cache.directory/tmp/hive/_resultscache_
3
*hive.server2.trusted.domain.use.xff.headerfalse
=
#hive.server2.webui.spnego.principalHTTP/_HOST@EXAMPLE.COM

hive.merge.mapredfilesfalse
R
>yarn.nodemanager.runtime.linux.runc.allowed-container-networkshost,none,bridge
9
0hadoop.kerberos.keytab.login.autorenewal.enabledfalse
"
hive.cache.expr.evaluationtrue
5
-hive.compactor.cleaner.retention.time.seconds300s
2
 datanucleus.transactionIsolationread-committed
2
"yarn.nodemanager.localizer.address0.0.0.0:8040
3
-mapreduce.shuffle.pathcache.concurrency-level16
1
)hive.llap.io.allocator.max.force.eviction16Mb
`
)fs.viewfs.overload.scheme.target.oss.impl3org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem
(
!hive.metastore.batch.retrieve.max300
%
hive.binary.record.max.length1000
*
$yarn.nodemanager.resource.cpu-vcores-1
0
)hive.txn.acid.metrics.delta.num.threshold100
+
"dfs.client.failover.resolve-neededfalse
(
hive.mapjoin.check.memory.rows100000
?
2hive.llap.daemon.task.preemption.metrics.intervals	30,60,300
'
"hive.llap.io.allocator.arena.count8
5
,hive.llap.daemon.shuffle.dir.watcher.enabledfalse
%
 hive.txn.retrysnapshot.max.count5

hive.optimize.topnkeytrue
<
1hive.llap.task.communicator.connection.timeout.ms16000ms
;
3hive.repl.load.partitions.with.data.copy.batch.size1000
=
7yarn.resourcemanager.node-ip-cache.expiry-interval-secs-1
9
3yarn.timeline-service.client.fd-clean-interval-secs60
H
fs.wasbs.impl7org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure
^
"hadoop.ssl.keystores.factory.class8org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory
'
"dfs.federation.router.reader.count1

hadoop.zk.num-retries1000
!
hive.transpose.aggr.joinfalse
5
+yarn.client.nodemanager-connect.max-wait-ms180000
/
(hive.llap.nodehealthchecks.tasktimeratio1.5
(
 hive.exec.drop.ignorenonexistenttrue

hive.druid.maxTries5
Õ
&hive.serdes.using.metastore.for.schemaªorg.apache.hadoop.hive.ql.io.orc.OrcSerde,org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe,org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe,org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe,org.apache.hadoop.hive.serde2.OpenCSVSerde

hive.llap.io.use.lrfutrue
<
4dfs.namenode.snapshotdiff.allow.snap-root-descendanttrue
1
,yarn.app.mapreduce.client-am.ipc.max-retries3
4
.dfs.federation.router.heartbeat-state.interval5s
-
%dfs.namenode.audit.log.async.blockingtrue
5
,hive.server2.thrift.resultset.max.fetch.size10000
<
3yarn.nodemanager.container-diagnostics-maximum-size10000
8
,ipc.[port_number].decay-scheduler.thresholds13,25,50
%
dfs.namenode.get-blocks.max-qps20
P
Gyarn.nodemanager.linux-container-executor.cgroups.strict-resource-usagefalse
5
%dfs.namenode.ec.system.default.policyRS-6-3-1024k
-
%dfs.federation.router.safemode.enabletrue
;
hive.exim.uri.scheme.whitelisthdfs,pfile,file,s3,s3a,gs
9
1hive.query.results.cache.wait.for.pending.resultstrue
(
#hive.tez.bloom.filter.merge.threads1
*
dfs.datanode.https.address0.0.0.0:9865
A
8hive.llap.external.client.cloud.deployment.setup.enabledfalse
&
 hive.io.sarg.cache.max.weight.mb10
"
dfs.ha.standby.checkpointstrue

ipc.client.kill.max10
4
,mapreduce.job.committer.setup.cleanup.neededtrue
.
%dfs.client.domain.socket.data.trafficfalse
8
/yarn.nodemanager.localizer.cache.target-size-mb10240
8
/hive.server2.clear.dangling.scratchdir.interval1800s
)
!hive.join.shortcut.unmatched.rowstrue
/
&dfs.namenode.enable.log.stale.datanodefalse

hive.druid.sleep.timePT10S
A
8hadoop.security.group.mapping.ldap.connection.timeout.ms60000
!
dfs.ha.allow.stale.readsfalse
`
!yarn.timeline-service.store-class;org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore
C
;yarn.resourcemanager.nm-container-queuing.queue-limit-stdev1.0f
'
"hive.query.recompilation.max.count1
'
!hive.server2.compile.lock.timeout0s
"
hadoop.tmp.dir/tmp/hadoop-root
G
>dfs.namenode.block-placement-policy.exclude-slow-nodes.enabledfalse
%
hive.metastore.event.clean.freq0s
%
fs.s3a.etag.checksum.enabledfalse

hive.stageid.rearrangenone
/
'dfs.namenode.snapshotdiff.listing.limit1000

fs.s3a.retry.interval500ms
*
%dfs.datanode.http.internal-proxy.port0
,
!hive.exec.temporary.table.storagedefault
-
"hive.vectorized.groupby.maxentries1000000
(
 hive.mapjoin.optimized.hashtabletrue
K
Cyarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms1000
E
!tez.runtime.internal.sorter.class org.apache.hadoop.util.QuickSort
'
hive.remove.orderby.in.subquerytrue
G
>yarn.nodemanager.runtime.linux.runc.host-pid-namespace.allowedfalse
B
yarn.nodemanager.recovery.dir!/tmp/hadoop-root/yarn-nm-recovery
.
)dfs.namenode.max.full.block.report.leases6
$
dfs.namenode.caching.enabledtrue
)
 fs.s3a.select.errors.include.sqlfalse
H
&dfs.webhdfs.user.provider.user.pattern^[A-Za-z_][A-Za-z0-9._-]*[$]?$

yarn.webapp.ui2.enablefalse
/
 hive.arrow.batch.allocator.limit10000000000
"
hive.fetch.task.conversionmore

mapreduce.map.log.levelINFO
+
&dfs.datanode.ec.reconstruction.threads8
=
5yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms1000

hadoop.fuse.timer.period5
+
#ha.health-monitor.check-interval.ms1000
*
$hive.optimize.topnkey.partitions.max64
&
hive.server2.async.exec.threads100
.
&hive.llap.daemon.output.stream.timeout120s
3
*mapreduce.output.fileoutputformat.compressfalse
'
#javax.jdo.option.ConnectionPassword 
)
hive.transactional.events.mem10000000
7
/dfs.client.write.byte-array-manager.count-limit2048
?
6yarn.sharedcache.store.in-memory.staleness-period-mins10080
?
8yarn.nodemanager.runtime.linux.runc.layer-mounts-to-keep100
8
0hadoop.security.group.mapping.providers.combinedtrue
 
hive.llap.io.cache.onlyfalse
!
hive.tez.bmj.use.subcachetrue
/
yarn.nodemanager.webapp.address0.0.0.0:8042
$
mapreduce.job.running.map.limit0
9
2hive.txn.acid.metrics.obsolete.delta.num.threshold100
2
)hive.metastore.aggregate.stats.cache.size10000

hive.query.max.length10Mb

tez.am.max.app.attempts2

hive.session.silentfalse
C
>yarn.resourcemanager.placement-constraints.scheduler.pool-size1

fs.s3a.multipart.size64M
0
'dfs.client.slow.io.warning.threshold.ms30000
:
1yarn.app.mapreduce.am.job.committer.commit-window10000
5
/hive.server2.wm.delayed.move.validator.interval60
"
hive.optimize.point.lookuptrue
2
*tez.am.proportion.total.tasks.speculatable0.01
%
hive.llap.allow.permanent.fnstrue
'
dfs.namenode.edits.asyncloggingtrue
!
hive.llap.daemon.web.sslfalse
*
!hive.hmshandler.force.reload.conffalse
-
(dfs.blockreport.incremental.intervalMsec0
+
"datanucleus.schema.validateColumnsfalse
 
hive.prewarm.numcontainers10
-
datanucleus.identifierFactorydatanucleus1

hive.cli.errors.ignorefalse
ª
@yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-pluginforg.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.ImageTagToManifestPlugin
(
fs.s3a.s3guard.ddb.table.createfalse
8
0hive.optimize.bi.rewrite.percentile_disc.enabledtrue
%
dfs.client.socketcache.capacity16
%
 hive.llap.io.vrb.queue.limit.min1
<
3hive.txn.manager.dump.lock.state.on.acquire.timeoutfalse
,
'fs.s3a.select.input.csv.field.delimiter,
0
dfs.client.retry.policy.spec10000,6,60000,10
-
%hive.optimize.sampling.orderby.number1000
)
!dfs.namenode.reencrypt.batch.size1000
$
hive.server2.wm.pool.metricstrue
!
hive.ptf.valuecache.size10000

:hive.llap.external.client.cloud.jwt.shared.secret.providerCorg.apache.hadoop.hive.llap.security.DefaultJwtSharedSecretProvider
&
fs.s3a.connection.ssl.enabledfalse

hive.txn.xlock.writetrue
/
'tez.am.soonest.retry.after.no.speculate1000
*
#hive.repl.retry.backoff.coefficient1.2
-
$hive.repl.add.raw.reserved.namespacefalse
)
!hive.metastore.server.max.threads1000
)
!hive.metastore.try.direct.sql.ddltrue
,
"hive.mapjoin.hybridgrace.minwbsize524288
'
dfs.namenode.read.considerLoadfalse
(
!hadoop.security.groups.cache.secs300
!
hive.jdbc.pushdown.enabletrue
0
(dfs.federation.router.dn-report.time-out1000
(
dfs.datanode.peer.stats.enabledfalse
(
hive.acid.droppartition.usebasefalse
'
hive.resource.use.hdfs.locationtrue
)
 hive.server2.saml2.sp.force.authfalse
?
:dfs.storage.policy.satisfier.work.multiplier.per.iteration1

dfs.replication1
#
hive.enforce.bucketmapjoinfalse
D
;hadoop.security.group.mapping.ldap.directory.search.timeout10000
[
Ldfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold10737418240
*
hive.ssl.protocol.blacklistSSLv2,SSLv3
0
(tez.runtime.shuffle.memory.limit.percent0.25
&
dfs.checksum.combine.mode	MD5MD5CRC
;
2dfs.storage.policy.satisfier.max.outstanding.paths10000
+
#hive.compactor.abortedtxn.threshold1000
5
.yarn.nodemanager.sleep-delay-before-sigkill.ms250

hive.map.aggrtrue
`
(javax.jdo.PersistenceManagerFactoryClass4org.datanucleus.api.jdo.JDOPersistenceManagerFactory

fs.automatic.closetrue
,
%hive.stats.num.nulls.estimate.percent5.0
*
 hive.parquet.timestamp.time.unitmicros
)
#dfs.namenode.reencrypt.edek.threads10
N
Fyarn.nodemanager.disk-health-checker.disk-free-space-threshold.enabledtrue
+
$hive.optimize.bi.rewrite.rank.sketchkll
!
dfs.namenode.acls.enabledtrue
.
#hive.repl.cm.encryptionzone.rootdir.cmroot
>
3dfs.client.short.circuit.replica.stale.threshold.ms1800000
;
2yarn.nodemanager.health-checker.run-before-startupfalse
&
dfs.namenode.send.qop.enabledfalse
-
&dfs.namenode.slowpeer.collect.interval30m
`
*mapreduce.jobhistory.intermediate-done-dir2/tmp/hadoop-yarn/staging/history/done_intermediate
8
-dfs.client.server-defaults.validity.period.ms3600000
)
!mapreduce.client.libjars.wildcardtrue
%
dfs.federation.router.cache.ttl1m
5
.hive.mapjoin.optimized.hashtable.probe.percent0.5
$
hive.use.googleregex.enginefalse
1
$dfs.storage.policy.satisfier.address	0.0.0.0:0
!
hive.ptf.rangecache.size10000
%
dfs.namenode.audit.loggersdefault

hive.llap.io.acidtrue
Ê
io.serializations´org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization
E
!hive.metastore.kerberos.principal hive-metastore/_HOST@EXAMPLE.COM
9
(hadoop.http.cross-origin.allowed-methodsGET,POST,HEAD
>
5hive.llap.task.scheduler.node.reenable.min.timeout.ms200ms
0
'dfs.namenode.snapshot.capture.openfilesfalse
(
"dfs.qjournal.queued-edits.limit.mb10
#
hadoop.zk.aclworld:anyone:rwcda
1
)hive.support.special.characters.tablenametrue

hive.llap.validate.aclstrue
<
3hive.llap.external.client.cloud.output.service.port30005
>
6hive.repl.bootstrap.dump.abort.write.txn.after.timeouttrue
@
)yarn.nodemanager.container.stderr.pattern{*stderr*,*STDERR*}
<
mapreduce.cluster.local.dir/tmp/hadoop-root/mapred/local
Q
$ipc.[port_number].cost-provider.impl)org.apache.hadoop.ipc.DefaultCostProvider
&
hadoop.kerberos.kinit.commandkinit

list.sink.output.protocol7
1
*dfs.namenode.metrics.logger.period.seconds600
%
hive.txn.filter.delete.eventstrue
f
+fs.viewfs.overload.scheme.target.abfss.impl7org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem
&
dfs.block.access.token.lifetime600
7
*dfs.namenode.delegation.token.max-lifetime	604800000
.
%dfs.datanode.drop.cache.behind.writesfalse
1
)hive.server2.thrift.http.cookie.is.securetrue
&
hive.llap.zk.sm.session.timeout40s
N
Eyarn.resourcemanager.submission-preprocessor.file-refresh-interval-ms60000
:
5dfs.federation.router.connect.max.retries.on.timeouts0
!
hive.stats.list.num.entries10
0
%dfs.namenode.num.extra.edits.retained1000000
w
 dfs.block.placement.ec.classnameSorg.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant
0
*ipc.client.connect.max.retries.on.timeouts45
+
"fs.client.resolve.topology.enabledfalse
0
(hive.llap.io.encode.vector.serde.enabledtrue
*
!dfs.qjournal.http.open.timeout.ms60000
(
!hive.server2.thrift.login.timeout20s
3
+ha.health-monitor.connect-retry-interval.ms1000
5
-dfs.namenode.edekcacheloader.initial.delay.ms3000
,
$dfs.client.failover.resolver.useFQDNtrue
+
#hive.hashtable.key.count.adjustment0.99
-
$hive.metastore.integral.jdo.pushdownfalse
 
io.mapfile.bloom.size1048576
%
dfs.client-write-packet-size65536
@
fs.ftp.data.connection.mode!ACTIVE_LOCAL_DATA_CONNECTION_MODE
/
'hive.scheduled.queries.executor.enabledtrue
I
fs.swift.impl8org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem
+
&yarn.app.mapreduce.shuffle.log.backups0
,
'dfs.namenode.kerberos.principal.pattern*
0
(hive.vectorized.execution.reduce.enabledtrue
)
"dfs.webhdfs.socket.connect-timeout60s
6
-yarn.resourcemanager.scheduler.monitor.enablefalse
)
"hive.compactor.delta.pct.threshold0.1
:
4hive.vectorized.ptf.max.memory.buffering.batch.count25
*
"dfs.federation.router.admin.enabletrue
-
(fs.s3a.select.output.csv.quote.character"
)
mapreduce.task.stuck.timeout-ms600000
&
hadoop.security.authorizationfalse
"
hive.optimize.index.filtertrue
1
(hive.optimize.dynamic.partition.hashjoinfalse
%
yarn.timeline-service.version1.0f
4
-hive.optimize.bi.rewrite.countdistinct.sketchhll
,
$hive.llap.task.scheduler.am.registryllap
#
hive.exec.copyfile.maxnumfiles1
5
+yarn.am.liveness-monitor.expiry-interval-ms600000
5
#hive.druid.overlord.address.defaultlocalhost:8090
<
1hive.tez.dynamic.partition.pruning.max.event.size1048576

hive.cbo.enabletrue
+
#hive.optimize.remove.sq_count_checktrue
2
-hive.optimize.reducededuplication.min.reducer4
S
1yarn.timeline-service.leveldb-timeline-store.path/tmp/hadoop-root/yarn/timeline
+
%dfs.federation.router.connect.timeout2s
@
:dfs.federation.router.store.membership.expiration.deletion-1
3
,hive.map.aggr.hash.min.reduction.lower.bound0.4
%
hive.server2.max.start.attempts30
-
 hive.exec.dynamic.partition.mode	nonstrict
-
&hive.server2.thrift.max.worker.threads500
?
2yarn.resourcemanager.delegation.token.max-lifetime	604800000
:
2yarn.resourcemanager.ha.automatic-failover.enabledtrue
(
#tez.runtime.shuffle.parallel.copies5
(
#hive.basic.stats.max.threads.factor2
#
hive.cbo.costmodel.network150.0
+
!dfs.datanode.socket.write.timeout480000
,
!dfs.namenode.accesstime.precision3600000
:
2hadoop.security.group.mapping.ldap.conversion.rulenone
#
hive.druid.http.numConnection20
'
hive.server2.webui.enable.corsfalse
$
io.mapfile.bloom.error.rate0.005
%
hive.session.history.enabledfalse
2
)yarn.nodemanager.webapp.rest-csrf.enabledfalse
P
.yarn.timeline-service.leveldb-state-store.path/tmp/hadoop-root/yarn/timeline
!
hadoop.proxyuser.hive.groups*
?
1yarn.scheduler.configuration.zk-store.parent-path
/confstore
)
 ipc.[port_number].backoff.enablefalse
9
3yarn.timeline-service.writer.flush-interval-seconds60
2
*dfs.namenode.posix.acl.inheritance.enabledtrue
,
%dfs.datanode.outliers.report.interval30m
D
<hadoop.security.kms.client.encrypted.key.cache.low-watermark0.3f
 
dfs.namenode.top.enabledtrue
+
"hive.acid.renamepartition.makecopyfalse
%
hive.exec.check.crossproductstrue
'
fs.s3a.retry.throttle.interval100ms
D
3mapreduce.jobhistory.webapp.rest-csrf.custom-headerX-XSRF-Header
&
yarn.webapp.xfs-filter.enabledtrue
!
dfs.client.cached.conn.retry3
&
hive.optimize.constraints.jointrue
A
hive.exec.perf.logger(org.apache.hadoop.hive.ql.log.PerfLogger
œ
.hive.vectorized.row.serde.inputformat.excludesjorg.apache.parquet.hadoop.ParquetInputFormat,org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
=
4yarn.resourcemanager.submission-preprocessor.enabledfalse
Ž
hadoop.system.tagsxYARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT
      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL
]
Wyarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.num-manifests-to-cache10
3
,datanucleus.plugin.pluginRegistryBundleCheckLOG
?
+yarn.nodemanager.numa-awareness.numactl.cmd/usr/bin/numactl
:
1dfs.namenode.path.based.cache.refresh.interval.ms30000
5
*dfs.namenode.fs-limits.max-directory-items1048576
%
hive.llap.io.encode.slice.lrrtrue
%
 hive.exec.parallel.thread.number8

dfs.ha.log-roll.period120s
(
 dfs.datanode.pmem.cache.recoverytrue
8
/yarn.nodemanager.distributed-scheduling.enabledfalse
%
yarn.minicluster.fixed.portsfalse
0
(dfs.storage.policy.satisfier.queue.limit1000

hive.locks.max.partitions-1
>
4hive.metastore.aggregate.stats.cache.max.reader.wait1000ms
w
-hive.security.metastore.authenticator.managerForg.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
1
'hive.query.reexecution.stats.cache.size100000
>
7yarn.nodemanager.resource.percentage-physical-cpu-limit100
4
,hive.server2.thrift.http.request.header.size6144
.
%dfs.namenode.fs-limits.max-xattr-size16384
$
hive.server2.webui.max.threads50
1
,hive.optimize.limittranspose.reductiontuples0

hive.test.rollbacktxnfalse
7
.dfs.namenode.blocks.per.postponedblocks.rescan10000

hive.llap.daemon.acl*
"
hive.txn.readonly.enabledfalse
-
(dfs.namenode.maintenance.replication.min1
$
dfs.namenode.max.op.size52428800
$
hive.hook.proto.queue.capacity64
9
3yarn.timeline-service.app-aggregation-interval-secs15
<
5mapreduce.job.reducer.unconditional-preempt.delay.sec300
3
*yarn.app.mapreduce.am.hard-kill-timeout-ms10000
&
hive.tez.enable.memory.managertrue
#
hive.msck.repair.batch.size3000
6
-dfs.storage.policy.permissions.superuser-onlyfalse

fs.df.interval60000
/
'hive.optimize.view.tables.cache.enabledtrue
+
$fs.s3a.assumed.role.session.duration30m
5
-hive.metadata.move.exported.metadata.to.trashtrue
5
0mapreduce.job.cache.limit.max-single-resource-mb0
/
)dfs.disk.balancer.block.tolerance.percent10
)
 dfs.webhdfs.netty.high.watermark65535
&
hive.optimize.scan.probedecodetrue
0
)dfs.datanode.balance.max.concurrent.moves100
.
&hive.resultset.use.unique.column.namestrue
*
%hive.zookeeper.connection.max.retries3
=
5hive.security.authorization.tables.on.storagehandlerstrue
 
parquet.memory.pool.ratio0.5
"
hive.stats.filter.in.factor1.0
1
(mapreduce.job.token.tracking.ids.enabledfalse
a
(fs.s3a.assumed.role.credentials.provider5org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
3
*hive.server2.show.operation.drilldown.linkfalse
<
4hadoop.security.kms.client.failover.sleep.max.millis2000
D
3yarn.resourcemanager.webapp.rest-csrf.custom-headerX-XSRF-Header
7
/hive.test.vectorized.execution.enabled.overridenone
+
&mapreduce.jobhistory.move.thread-count3
/
(hive.txn.acid.metrics.reporting.interval30s
,
#hive.io.rcfile.tolerate.corruptionsfalse
(
#hive.exec.input.listing.max.threads0
J
Byarn.timeline-service.http-authentication.simple.anonymous.allowedtrue
+
%hive.autogen.columnalias.prefix.label_c
1
"hive.zookeeper.killquery.namespacekillQueries
&
dfs.namenode.provided.enabledfalse
1
+yarn.sharedcache.client-server.thread-count50
#
fs.s3a.s3guard.ddb.max.retries9
/
'hive.repl.copy.file.list.iterator.retrytrue
/
(yarn.scheduler.configuration.max.version100
(
"mapreduce.jobhistory.jobname.limit50
3
+yarn.dispatcher.print-events-info.threshold5000
1
*hive.optimize.topnkey.efficiency.threshold0.8
7
-dfs.namenode.decommission.blocks.per.interval500000
)
!hive.server2.webui.explain.outputtrue
+
"dfs.qjournal.write-txns.timeout.ms20000
|
)yarn.federation.subcluster-resolver.classOorg.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl
5
-dfs.namenode.read-lock-reporting-threshold-ms5000
)
#yarn.nodemanager.resource.memory-mb-1
L
=yarn.nodemanager.container-log-monitor.total-size-limit-bytes10000000000

hive.llap.plugin.rpc.port0
!
mapreduce.framework.namelocal
4
/mapreduce.fileoutputcommitter.algorithm.version2
,
!hive.lock.query.string.max.length1000000
€
/yarn.router.clientrm.interceptor-class.pipelineMorg.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor

hive.exec.rowoffsetfalse
&
hive.llap.io.track.cache.usagetrue
(
 hive.ppd.remove.duplicatefilterstrue
"
yarn.sharedcache.nested-level3
5
,hadoop.security.dns.log-slow-lookups.enabledfalse
:
)mapreduce.jobhistory.webapp.https.address0.0.0.0:19890
&
file.client-write-packet-size65536
;
2hive.server2.authentication.jwt.jwks.skip.ssl.certfalse
&
!hive.llap.daemon.rpc.num.handlers5

ipc.client.pingtrue
#
hive.count.open.txns.interval1s
$
hive.repl.retry.initial.delay60s
5
,hive.metastore.aggregate.stats.cache.enabledfalse
*
!dfs.balancer.max-no-move-interval60000
5
,yarn.minicluster.control-resource-monitoringfalse
!
dfs.disk.balancer.enabledtrue
'
!hive.hook.proto.events.clean.freq1d
4
/yarn.resourcemanager.fs.state-store.num-retries0
 
hive.use.orc.codec.poolfalse
'
hadoop.security.uid.cache.secs14400
P
7yarn.resourcemanager.ha.automatic-failover.zk-base-path/yarn-leader-election

hive.heartbeat.interval1000
'
"hive.txn.heartbeat.threadpool.size5
&
hive.lock.sleep.between.retries60s

hive.test.mode.samplefreq32
#
hive.server2.authenticationNONE
”
#dfs.datanode.du.reserved.calculatormorg.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReservedSpaceCalculator$ReservedSpaceCalculatorAbsolute
1
,dfs.datanode.block.id.layout.upgrade.threads6
<
6dfs.federation.router.store.router.expiration.deletion-1
/
!hive.query.results.cache.max.size
2147483648
.
'hive.server2.async.exec.wait.queue.size100
4
+yarn.client.load.resource-types.from-serverfalse
/
(dfs.federation.router.safemode.extension30s
#
hive.auto.convert.anti.jointrue

hive.explain.userfalse
=
7yarn.client.application-client-protocol.poll-timeout-ms-1
)
dfs.datanode.oob.timeout-ms
1500,0,0,0
:
3dfs.federation.router.connection.creator.queue-size100
#
hive.metastore.connect.retries3
*
mapreduce.job.sharedcache.modedisabled
%
 yarn.resourcemanager.epoch.range0
(
 hive.strict.timestamp.conversiontrue
F
Ahadoop.security.kms.client.encrypted.key.cache.num.refill.threads2
H
-hive.metastore.archive.intermediate.extracted_INTERMEDIATE_EXTRACTED
#
tez.runtime.ifile.readaheadtrue
/
)hive.repl.bootstrap.dump.open.txn.timeout1h
0
(dfs.namenode.edekcacheloader.interval.ms1000
`
5yarn.nodemanager.aux-services.mapreduce_shuffle.class'org.apache.hadoop.mapred.ShuffleHandler
D
?hadoop.security.group.mapping.ldap.num.attempts.before.failover3

fs.du.interval600000
;
4hive.cardinality.preserving.join.optimization.factor1.0

tez.submit.hosthive
%
hive.cbo.costmodel.hdfs.write10.0
*
!dfs.client.read.uri.cache.enabledfalse
+
#dfs.data.transfer.server.tcpnodelaytrue
#
hadoop.zk.retry-interval-ms1000
+
%dfs.http.client.failover.max.attempts15
"
hive.msck.path.validationthrow
8
3dfs.client.block.write.locateFollowingBlock.retries5
!
fs.s3a.socket.send.buffer8192
´
&mapreduce.jvm.system-properties-to-log‰os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name
&
dfs.namenode.enable.retrycachetrue
%
hive.merge.size.per.task	256000000
v
Myarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidia-docker-v1.endpoint%http://localhost:3476/v1.0/docker/cli
:
3mapreduce.job.encrypted-intermediate-data.buffer.kb128
!
hive.stats.max.num.stats10000
+
#dfs.data.transfer.client.tcpnodelaytrue
)
!dfs.storage.policy.satisfier.modenone
$
hive.txn.strict.locking.modetrue
C
5yarn.resourcemanager.webapp.xfs-filter.xframe-options
SAMEORIGIN
,
&hive.compactor.history.reaper.interval2m
 
mapreduce.reduce.memory.mb-1
&
hadoop.caller.context.enabledfalse
J
Cyarn.resourcemanager.nodemanagers.heartbeat-interval-speedup-factor1.0
2
(dfs.qjournal.prepare-recovery.timeout.ms120000
š
%hadoop.security.sensitive-config-keysð
      secret$
      password$
      ssl.keystore.pass$
      fs.s3a.server-side-encryption.key
      fs.s3a.*.server-side-encryption.key
      fs.s3a.secret.key
      fs.s3a.*.secret.key
      fs.s3a.session.key
      fs.s3a.*.session.key
      fs.s3a.session.token
      fs.s3a.*.session.token
      fs.azure.account.key.*
      fs.azure.oauth2.*
      fs.adl.oauth2.*
      credential$
      oauth.*secret
      oauth.*password
      oauth.*token
      hadoop.security.sensitive-config-keys
  
,
#hive.groupby.orderby.position.aliasfalse
0
(mapreduce.client.completion.pollinterval5000

hive.mapjoin.full.outertrue
1
)hive.tez.input.generate.consistent.splitstrue
3
#dfs.namenode.secondary.http-address0.0.0.0:9868
9
)yarn.resourcemanager.webapp.https.address0.0.0.0:8090
!
hive.server2.enable.doAsfalse
!
fs.s3a.retry.throttle.limit20
.
%dfs.permissions.allow.owner.set.quotafalse
N
hadoop.domainname.resolver.impl+org.apache.hadoop.net.DNSDomainNameResolver
'
!hive.server2.idle.session.timeout4h
$
fs.s3a.endpointhttp://minio:9000
H
tez.runtime.compress.codec*org.apache.hadoop.io.compress.DefaultCodec